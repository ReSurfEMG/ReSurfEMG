{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on EMG analysis\n",
    "This notebook allows a researcher to collect data on a set of EMG. The data are collected for each breath and include total area under breath curve, maximum value in each breath, legnth of breaths, and relative location of maximum value(as both raw and percentage of total breath)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "import collections\n",
    "from collections import namedtuple\n",
    "import builtins\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing from machine\n",
    "# import sys\n",
    "# sys.path.insert(0, '../resurfemg')\n",
    "# from config import Config\n",
    "# import helper_functions as hf\n",
    "# from tmsisdk_lite import Poly5Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resurfemg.config import Config\n",
    "from resurfemg.tmsisdk_lite import Poly5Reader\n",
    "import resurfemg.helper_functions as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a collection place for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not rerun this cell\n",
    "big_data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below change the path to the root directory where you are keeping your EMGs and ventilator \"Draeger\" files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reruns should be done from this cell as the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "root_emg_directory = config.get_directory('root_emg_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_pattern = os.path.join(root_emg_directory, '**/*.Poly5')\n",
    "emg_and_draeger_files = glob.glob(emg_pattern, recursive=True)\n",
    "\n",
    "emg_files = []\n",
    "draeger_files = []\n",
    "\n",
    "for file in emg_and_draeger_files:\n",
    "    if 'Draeger' in file:\n",
    "        draeger_files.append(file)\n",
    "    else:\n",
    "        emg_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can pick a file from the list, which have been numbered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_numbers_strung = []\n",
    "for i in range(len(emg_files)):\n",
    "    list_of_numbers_strung.append(str(i))\n",
    "\n",
    "\n",
    "btn = widgets.Dropdown(\n",
    "    options=list_of_numbers_strung,\n",
    "    value='0',\n",
    "    description='Picked File:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(btn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caution! \n",
    "If you folder is set up in any way different then the picked file numbers will not neccesarily correspond to the same file. Always check the print out for the file you have chosen in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_chosen = int(btn.value)\n",
    "file_chosen = emg_files[number_chosen] \n",
    "print(\"The file you chose is:\",file_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_emg = Poly5Reader(file_chosen)\n",
    "data_samples= data_emg.samples\n",
    "emg_sample_rate = data_emg.sample_rate\n",
    "converted_to_seconds =  []\n",
    "converted_to_samples = []\n",
    "for i in range(len(data_samples[0])):\n",
    "    converted_to_seconds.append(i/emg_sample_rate)\n",
    "    converted_to_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "x = data_samples\n",
    "fig, axis = plt.subplots(nrows = 3, ncols = 2, figsize=(6, 6))\n",
    "axis[0,0].grid(True)\n",
    "axis[0,0].plot(x[0])\n",
    "axis[0,0].set(title='leads in samples')\n",
    "axis[1,0].plot(x[1])\n",
    "axis[2,0].plot(x[2])\n",
    "axis[0,1].set(title='leads in seconds')\n",
    "axis[0,1].grid(True)\n",
    "axis[0,1].plot(converted_to_seconds,x[0])\n",
    "axis[1,1].plot(converted_to_seconds,x[1])\n",
    "axis[2,1].plot(converted_to_seconds,x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the whole unfiltered EMG, but you probably want to examine a part. You will also want to examine something filtered down to only the EMG components. Therefore we will filter off only the EMG components with an ICA in addtion to the filter we will play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can filter down to which part you want to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you want to cut and see the file in samples or seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = widgets.Dropdown(\n",
    "    options=[\"Samples\",\"Seconds\"],\n",
    "    value='Samples',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(y_axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_view= y_axis.value\n",
    "time_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will pick the start and end of your sample.We are going to clip the end of the sample in processing, so you can not pick any values and get a good graph. We preset the values towards the max graphable with ease, but they can be overwritten.  In the future we will have an updating graph here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_view == 'Samples':\n",
    "    int_slider1 = widgets.IntSlider(\n",
    "        min=0, max=int(len(x[0])*0.89), step=1,\n",
    "        description=' samples start'\n",
    "    )\n",
    "    int_slider2 = widgets.IntSlider(\n",
    "        value=len(x[0]),\n",
    "        min=0, max=int(len(x[0])*0.89), step=1,\n",
    "        description='samples end cutoff'\n",
    "    )\n",
    "else:\n",
    "    int_slider1 = widgets.IntSlider(\n",
    "        #value=0.1,\n",
    "        min=0, max= int(converted_to_seconds[-1])*0.89, step=1,\n",
    "        description='seconds start'\n",
    "    )\n",
    "    int_slider2 = widgets.IntSlider(\n",
    "        #value=converted_to_seconds[-1],\n",
    "        min=0, max=int(converted_to_seconds[-1])*0.89, step= 1,\n",
    "        description='seconds end cutoff'\n",
    "    )\n",
    "    \n",
    "widgets.VBox(\n",
    "    [\n",
    "\n",
    "        int_slider1,\n",
    "        int_slider2,\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can overwrite the values by hand in the next cell, if scrolling is not precise enough...but rewriting to take an absolute end is unadvisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Here we can overwrite the values by hand, again you must pick values a bit inside\n",
    "# int_slider1.value = 1\n",
    "# int_slider2.value = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will graph your choice in the next active cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int_slider1.value\n",
    "end= int_slider2.value\n",
    "if time_view == 'Samples':\n",
    "    # nox examine at a certain scale- from point a to b as samples\n",
    "    x = data_samples\n",
    "    fig, (ax_1,ax_2,ax_3) = plt.subplots(nrows = 3, figsize=(6, 4))\n",
    "    ax_1.grid(True)\n",
    "    ax_1.plot(x[0][int(start):int(end)])\n",
    "    ax_1.set(title='leads, samples')\n",
    "    ax_2.plot(x[1][int(start):int(end)])\n",
    "    ax_3.plot(x[2][int(start):int(end)])\n",
    "    \n",
    "if time_view == 'Seconds':\n",
    "    # nox examine at a certain scale- from point a to b as samples\n",
    "    x_for_secs = data_samples\n",
    "\n",
    "    y = converted_to_seconds\n",
    "    fig, (ax_1,ax_2,ax_3) = plt.subplots(nrows = 3, figsize=(6, 4))\n",
    "    ax_1.grid(True)\n",
    "    ax_1.plot(y[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[0][int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "    ax_1.set(title='leads, seconds')\n",
    "    ax_2.plot(y[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[1][int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "    ax_3.plot(y[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[2][int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy with your selection? If not redo the widgeted cell, then we can see how the filter the selection in a basic pipleline before extracting entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropdown to pick ICA possibilities. CUrrently only one -\\o/-\n",
    "ICA_choice = widgets.Dropdown(\n",
    "    options=[\"classic\",\"no_ica_lead3\"],\n",
    "    value='classic',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(ICA_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will have to rewrite to accomodate different ICAs, but this is in the future. After we iron out the alternative ICAs. Below we put our EMG data through the pipeline we have now, and we must do picking from an ICA by more peaks or by dis-similarity to the heart/ECG lead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_picker_choice = widgets.Dropdown(\n",
    "    options=[\"more_peaks\",\"similar_to_ECG\"],\n",
    "    value='more_peaks',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(ICA_picker_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_picker_choice.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's examine our processed EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ICA_picker_choice.value == 'more_peaks':\n",
    "    processed_data_emg = hf.working_pipeline_pre_ml(data_samples,picker='peaks')\n",
    "elif ICA_picker_choice.value == 'similar_to_ECG':\n",
    "    processed_data_emg = hf.working_pipeline_pre_ml(data_samples,picker='heart')\n",
    "else:\n",
    "    processed_data_emg = hf.working_pipeline_pre_ml(data_samples,picker='heart')\n",
    "\n",
    "if time_view == 'Seconds':\n",
    "    %matplotlib inline\n",
    "    # set up plotn\n",
    "    x = processed_data_emg\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize=(14, 6))\n",
    "    axis[0].grid(True)\n",
    "    axis[0].plot(converted_to_seconds[:len(x)], x)\n",
    "    axis[0].set(title='The whole sample minus last filter lost end')\n",
    "    axis[1].set(title='Your picked area in seconds')\n",
    "    axis[1].grid(True)\n",
    "    axis[1].plot(converted_to_seconds[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "else:\n",
    "    %matplotlib inline\n",
    "    x = processed_data_emg\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize=(14, 6))\n",
    "    axis[0].grid(True)\n",
    "    axis[0].plot(x)\n",
    "    axis[0].set(title='The whole sample minus last filter lost end')\n",
    "    axis[1].set(title='Your picked area in samples')\n",
    "    axis[1].grid(True)\n",
    "    axis[1].plot(converted_to_samples[int(start):int(end)],x[int(start):int(end)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we created some basic processed EMG. Now we need to determine where the breaths are. We will graph the results to make sure we are happy with the. The cutoff forsample selected will be based on entropy here. You ultimately do a cut-off based on something popular in the literature, or your own ideas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we want to look in seconds later\n",
    "start_s= start * emg_sample_rate\n",
    "end_s = end * emg_sample_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above picture the green line represents a 0,1, array which represents the breaths. That picking was based on one simple parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do picking of breaths based on identifying places in teh signal with 90%  or more of max entropy, then including from there places with  50% or more this will give start of breath with smoothing of the array if there is too short a pause. This is a more complicated algorithm than an arbitrary baseline, but gives good results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder\n",
    "time_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rounded_for_ent(stralist):\n",
    "    rounded= np.round_(stralist, decimals = 5)\n",
    "    return rounded\n",
    "if time_view == 'Samples':\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start):int(end)])# replace with whole array of time series!\n",
    "else:\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start_s):int(end_s)])\n",
    "slice_length = 100\n",
    "def sliceIterator(lst, sliceLen):\n",
    "    for i in range(len(lst) - sliceLen + 1):\n",
    "        yield lst[i:i + sliceLen]\n",
    "index_hold = []\n",
    "for slice in sliceIterator(big_list, slice_length):\n",
    "    entropy_index = hf.entropical(slice)\n",
    "    index_hold.append(entropy_index)\n",
    "\n",
    "high_decision_cutoff = 0.9  * ((np.max(index_hold)) - (np.min(index_hold))) + np.min(index_hold)\n",
    "decision_cutoff = 0.5 * ((np.max(index_hold)) - (np.min(index_hold))) + np.min(index_hold)\n",
    "\n",
    "rms_rolled = hf.vect_naive_rolling_rms(index_hold,100) # so rms is rms entropy\n",
    "\n",
    "\n",
    "if time_view == 'Samples':\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],processed_data_emg[int(start):(int(start) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],rms_rolled)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color= 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    \n",
    "else:\n",
    "    y = converted_to_seconds\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))], processed_data_emg[int(start_s):(int(start_s)+len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],rms_rolled)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color = 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.array(hf.zero_one_for_jumps_base(rms_rolled, high_decision_cutoff))\n",
    "lo = np.array(hf.zero_one_for_jumps_base(rms_rolled, decision_cutoff))\n",
    "\n",
    "rhi = hf.ranges_of(hi)\n",
    "rlo = hf.ranges_of(lo)\n",
    "\n",
    "keep = hf.intersections(rlo, rhi)\n",
    "\n",
    "\n",
    "points = np.array(sum(keep, start=()), dtype=np.int32)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_line = np.zeros(len(rms_rolled))\n",
    "for seven_range in keep:\n",
    "    seven_line[seven_range.to_slice()] = 7\n",
    "if time_view == 'Samples':\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],processed_data_emg[int(start):(int(start) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff),  color = 'green')\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],(np.array(hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff)))*2, color= 'purple')\n",
    "    #plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))], six_line)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))], seven_line)\n",
    "else:\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))],processed_data_emg[int(start_s):(int(start_s) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff),  color = 'green')\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))],(np.array(hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff)))*2, color= 'purple')\n",
    "    #plt.plot(converted_tosecondss[int(star_st):(int(star_st) + len(rms_rolled))], six_line)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))], seven_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above our 'seven-line' represents picking based on finding areas with 90% max entropy, then picking evything around them with over 50% entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened in these breaths?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know:\n",
    "legnth of breaths,\n",
    "relative location of maximum value inside the breath(as both raw and percentage of total breath),\n",
    "the area under the curve for each breath- total area per breath,\n",
    "then the area to where we cross back over 70% of peak values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to figure out which elements of grouped are breath parts, and make arrays of just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so grouped needs to be picked down to where at jump indeces we go up from 0 to 7\n",
    "our_emg_array_samples = processed_data_emg[int(start):(int(start) + len(rms_rolled))]\n",
    "our_emg_array_seconds = processed_data_emg[int(start_s):(int(start_s) + len(rms_rolled))]\n",
    "zippy = zip(seven_line,seven_line[1:])\n",
    "breath_indeces = []\n",
    "for val in enumerate(zippy):\n",
    "    if val[1][0] < val[1][1]:\n",
    "        print(val[0])\n",
    "        breath_indeces.append(val[0])\n",
    "if time_view == 'Samples':\n",
    "    grouped_breaths = np.split(our_emg_array_samples, breath_indeces)\n",
    "    grouped_entropy = np.split(rms_rolled, breath_indeces)\n",
    "    grouped_breaths = grouped_breaths[1:]\n",
    "    grouped_entropy = grouped_entropy[1:]\n",
    "\n",
    "else:\n",
    "    grouped_breaths = np.split(our_emg_array_seconds, breath_indeces)\n",
    "    grouped_entropy= np.split(rms_rolled, breath_indeces)\n",
    "    grouped_breaths = grouped_breaths[1:]\n",
    "    grouped_entropy = grouped_entropy[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many breaths did we catch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped_breaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in grouped_breaths:\n",
    "    group = abs(group)\n",
    "    plt.plot(group, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in grouped_entropy:\n",
    "     plt.plot(group, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We see we caught the breaths...notice they follow a typical pattern with entropy- we were counting on that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional cell to examine each breath by graphing it alone\n",
    "group = abs(grouped_breaths[30])\n",
    "plt.plot(group, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## legnth of each breath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "samples = []\n",
    "breath_number = list(range(len(grouped_breaths)))\n",
    "for i in breath_number:\n",
    "# for breath in grouped_breaths:\n",
    "    lengths.append(len(grouped_breaths[i]))\n",
    "    samples.append(i)\n",
    "d1 = {'samples': samples, 'lengths': lengths}\n",
    "df1 = pd.DataFrame(d1) \n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxima for each breath\n",
    "Note out  breaths contain positive and negative numbers...so we will make them positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima= []\n",
    "samples = []\n",
    "breath_number = list(range(len(grouped_breaths)))\n",
    "for i in breath_number:\n",
    "# for breath in grouped_breaths:\n",
    "    point = hf.find_peak_in_breath(abs(grouped_breaths[i]), 0,len(grouped_breaths[i]))\n",
    "    maxima.append(point)\n",
    "    samples.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note we will get a tuple of (where, how high)\n",
    "d2 = {'samples': samples, 'maxima': maxima}\n",
    "#d2 = {'samples': samples, 'maxima_loc': maxima_loc, 'maxima': maxima_height}\n",
    "df2 = pd.DataFrame(d2) \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxima location by percent\n",
    "Obviously if we merge the dataframes we can add a column for maximal location by percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1and2 = df1.merge(df2, on='samples')\n",
    "df_1and2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1and2['location_maxima'] = df_1and2.apply(lambda row: row['maxima'][0], axis=1)\n",
    "df_1and2['height_maxima'] = df_1and2.apply(lambda row: row['maxima'][1], axis=1)\n",
    "df_1and2['percent_forward_maxima'] = df_1and2['location_maxima'] /df_1and2['lengths']\n",
    "df_1and2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under curve\n",
    "Note out breaths are both poositive and negative values, so we will use absolute values...and we will merge onto our larger datafame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell below needs rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas_70 = []\n",
    "# simple_areas = []\n",
    "# samples = []\n",
    "# breath_number = list(range(len(grouped_breaths)))\n",
    "# for i in breath_number:\n",
    "# # for breath in grouped_breaths:\n",
    "#     area_70 = hf.area_under_curve(\n",
    "#         abs(grouped_breaths[i]),\n",
    "#         0,\n",
    "#         (len(grouped_breaths[i])-1),\n",
    "#         end_curve=70,\n",
    "#         smooth_algorithm='mid_savgol',\n",
    "#     )\n",
    "#     simple_area = np.sum(abs(grouped_breaths[i]))\n",
    "#     areas_70.append(area_70)\n",
    "#     simple_areas.append(simple_area)\n",
    "#     samples.append(i)\n",
    "# d3 = {'samples': samples, 'areas_70': areas_70, 'simple_AUC' : simple_areas}\n",
    "# df3 = pd.DataFrame(d3) \n",
    "# df123 = df_1and2.merge(df3, on = 'samples')\n",
    "# df123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
