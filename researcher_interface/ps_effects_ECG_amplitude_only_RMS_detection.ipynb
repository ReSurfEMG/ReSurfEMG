{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the effects of PS on P, TV, F, sEAdi etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-me\n",
    "<!-- TODO ... Insert description ... -->\n",
    "\n",
    "The code to consecutively:\n",
    "<!-- TODO  Update code steps-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import code libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard code libraries\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy\n",
    "from scipy import interpolate as interp\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "import neurokit2 as nk\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code libraries from the ReSurfEMG repository\n",
    "# It uses the ReSurfEMG library version v0.2.1\n",
    "\n",
    "import resurfemg.preprocessing.ecg_removal as ecg_rm\n",
    "import resurfemg.preprocessing.envelope as evl\n",
    "import resurfemg.preprocessing.filtering as filt\n",
    "import resurfemg.postprocessing.features as feat\n",
    "\n",
    "from resurfemg.data_connector.tmsisdk_lite import Poly5Reader\n",
    "\n",
    "from resurfemg.config.config import Config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_baseline(signal, fs, window_length):\n",
    "    #  Augmented moving baseline for EMGdi signals for baseline crossing detection\n",
    "\n",
    "    # 2.a. Calculate the \"default\" moving baseline over the sEAdi data over a 7.5s \n",
    "    #     window\n",
    "    rolling_baseline = np.zeros((len(signal), ))\n",
    "    for idx in range(0, len(signal), int(fs/5)):\n",
    "        start_i = max([0, idx-int(window_length/2)])\n",
    "        end_i = min([len(signal), idx+int(window_length/2)])\n",
    "        baseline_value = np.nanpercentile(signal[start_i:end_i], 33)\n",
    "        \n",
    "        for i in range(idx, min([idx+int(fs/5), len(signal)])):\n",
    "            rolling_baseline[i] = baseline_value\n",
    "    \n",
    "    return rolling_baseline\n",
    "\n",
    "def augmented_moving_baseline(signal, fs, window_length, augmented_perc):\n",
    "    # 2.a. Calculate the \"default\" moving baseline over the sEAdi data over \n",
    "    #       a 7.5s window\n",
    "    default_rolling_baseline = moving_baseline(signal, fs, window_length)\n",
    "\n",
    "    # 2.b. Rolling standard deviation and mean over 7.5s window\n",
    "    baseline_series = pd.Series(default_rolling_baseline)\n",
    "    baseline_std = baseline_series.rolling(window_length, \n",
    "                                    min_periods=1, \n",
    "                                    center=True).std().values\n",
    "    baseline_mean = baseline_series.rolling(window_length, \n",
    "                                    min_periods=1, \n",
    "                                    center=True).mean().values\n",
    "\n",
    "    # 2.c. Augmented signal: EMG + abs([dEMG/dt]_smoothed)\n",
    "    ma_window = fs//2\n",
    "    # augmented_perc = 25\n",
    "    perc_window = fs\n",
    "\n",
    "    s = pd.Series(signal - default_rolling_baseline)\n",
    "    s_MA = s.rolling(window=ma_window, center=True).mean().values\n",
    "    ds_dt = (s_MA[1:] - s_MA[:-1] ) * fs\n",
    "    s_aug = signal[:-1] + np.abs(ds_dt)\n",
    "\n",
    "    # 2.d. Run the moving median filter over the augmented signal to obtain the \n",
    "    #       baseline\n",
    "    s_aug_rolling_baseline = np.zeros(\n",
    "        (len(signal)-1, ))\n",
    "\n",
    "    for idx in range(0, int(len(signal)-1), perc_window):\n",
    "        start_i = max([0, idx-int(window_length)])\n",
    "        end_i = min([len(signal)-1, idx+int(window_length)])\n",
    "\n",
    "        baseline_value = np.nanpercentile(\n",
    "            s_aug[start_i:end_i], augmented_perc)\n",
    "        \n",
    "        for i in range(idx, min([idx+int(perc_window), len(signal)-1])):\n",
    "            s_aug_rolling_baseline[i] = 1.2 * baseline_value\n",
    "    \n",
    "    return s_aug_rolling_baseline, baseline_std, baseline_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation of output folder for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data path - The main directory where all data is loaded from\n",
    "root_patient_data_directory = \\\n",
    "    config.get_directory('root_patient_data_directory')\n",
    "\n",
    "# Output data - General path to dir for saving .csvs and plots\n",
    "main_output_dir = os.path.join(config.get_directory('preprocessed'),\n",
    "                    '2024-03_PS_exploration_QRS_detection_baseline_removal')\n",
    "\n",
    "if not os.path.exists(main_output_dir):\n",
    "    os.makedirs(main_output_dir)\n",
    "\n",
    "patient_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the ventilator and sEMG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a Select a patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the patient of interest\n",
    "# Expected data structure:\n",
    "# - Patient_01\n",
    "# -- Measurement_date_XXXX_XX_01\n",
    "# --- 001_Baseline\n",
    "# --- 002_PS_step_01\n",
    "# --- 003_PS_step_02\n",
    "# --- 004_PS_step_03\n",
    "# --- 005_PS_step_04\n",
    "# -- Measurement_date_XXXX_XX_03\n",
    "# --- 001_Baseline\n",
    "# --- 002_PS_step_01\n",
    "# --- 003_PS_step_02\n",
    "# --- 004_PS_step_03\n",
    "# --- 005_PS_step_04\n",
    "# -- Patient_02\n",
    "# -- Measurement_date_XXXX_XX_01\n",
    "# etc.\n",
    "\n",
    "# NB Run this cell once per patient!\n",
    "\n",
    "patient_folders = glob.glob(\n",
    "        os.path.join(root_patient_data_directory, '**',''), \n",
    "        recursive=False)\n",
    "\n",
    "patients = []\n",
    "for folder in patient_folders:\n",
    "    name = Path(folder).parts[-1]\n",
    "    patients.append(name)\n",
    "\n",
    "patients.sort()\n",
    "\n",
    "btn_pt = widgets.Dropdown(  \n",
    "    options=patients,\n",
    "    value=patients[patient_idx],\n",
    "    description='Select patient:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "date_idx = 0\n",
    "\n",
    "display(btn_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b Select a measurement date, or PS trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the PS trial of interest for the selected patient\n",
    "# measurement_date ~ PEEP-trial\n",
    " \n",
    "# NB Run this cell once per patient/PEEP trial combination\n",
    "\n",
    "patient = btn_pt.value\n",
    "patient_idx =btn_pt.index\n",
    "\n",
    "measurement_folders = glob.glob(\n",
    "    os.path.join(root_patient_data_directory, patient, '**',''),\n",
    "    recursive=False)\n",
    "measurement_dates = []\n",
    "\n",
    "for folder in measurement_folders:\n",
    "    name = Path(folder).parts[-1]\n",
    "    measurement_dates.append(name)\n",
    "\n",
    "measurement_dates.sort()\n",
    "\n",
    "# Initialise the analysis: empty the output parameter list and start at the \n",
    "# baseline measurement (index 0)\n",
    "di_data_list = []\n",
    "para_data_list = []\n",
    "Paw_data_list = []\n",
    "Vvent_data_list =[]\n",
    "ecg_data_list = []\n",
    "\n",
    "ecg_data_all_dict = dict()\n",
    "df_ecg_all_dict = dict()\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "columns_ecg_all = ['patient', 'measurement',\n",
    "              'ecg_minmax', 'ecg_min', 'ecg_max', 'ecg_method']\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    ecg_data_all_dict[channel] = []\n",
    "    df_ecg_all_dict[channel] = pd.DataFrame(ecg_data_all_dict[channel], columns=columns_ecg_all)\n",
    "\n",
    "PS_step_idx = 0\n",
    "plt.close('all')\n",
    "\n",
    "btn_measurement = widgets.Dropdown(\n",
    "    options=measurement_dates,\n",
    "    value=measurement_dates[date_idx],\n",
    "    description='Select measurement date:',\n",
    "    parasabled=False,\n",
    ")\n",
    "display(btn_measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default pipeline parameters\n",
    "# Gating settings\n",
    "gate_width_default = 0.10\n",
    "gate_threshold_default = 0.30\n",
    "gate_ECG_shift_default = -10\n",
    "gate_twice = False\n",
    "\n",
    "# RMS window\n",
    "RMS_window_ms_default = 200\n",
    "\n",
    "# Peak detection settings\n",
    "time_shift_default = 0.5 - RMS_window_ms_default/1000/2\n",
    "sEAdi_prominence_factor_default = 0.5\n",
    "sEApara_prominence_factor_default = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.c Select a PS step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the PS step of interest for the selected patient/measurement_date\n",
    "\n",
    "# NB Re-run this cell for each new PEEP trial, as it also empties output \n",
    "# parameter list (di_data_list)!\n",
    "\n",
    "\n",
    "# Create output data folders\n",
    "measurement_date = btn_measurement.value\n",
    "date_idx = btn_measurement.index\n",
    "\n",
    "output_path = os.path.join(main_output_dir, patient, measurement_date)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Identify all PS step folders:\n",
    "root_emg_directory = os.path.join(\n",
    "    root_patient_data_directory, patient, measurement_date)\n",
    "\n",
    "emg_pattern = os.path.join(root_emg_directory, '**/*.Poly5')\n",
    "emg_and_vent_files = glob.glob(emg_pattern, recursive=True)\n",
    "\n",
    "emg_files = []\n",
    "vent_files = []\n",
    "plt.close('all')\n",
    "\n",
    "for file in emg_and_vent_files:\n",
    "    if 'Draeger' in file:\n",
    "        vent_files.append(file)\n",
    "    else:\n",
    "        emg_files.append(file)\n",
    "\n",
    "emg_files.sort()\n",
    "vent_files.sort()\n",
    "\n",
    "list_of_numbers_string = []\n",
    "\n",
    "for i in range(len(emg_files)):\n",
    "    list_of_numbers_string.append(Path(emg_files[i]).parts[-2])\n",
    "\n",
    "# Select the PEEP step of interest. The selection menu initialises at the third \n",
    "# but last (index -4) recording. The PEEP steps are named after the folders \n",
    "# containing the data files (.poly5) of interest.\n",
    "\n",
    "btn_PS_step = widgets.Dropdown(\n",
    "    options=list_of_numbers_string,\n",
    "    value= list_of_numbers_string[PS_step_idx],\n",
    "    description='Picked File:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(btn_PS_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process selected option: the PEEP step of interest  \n",
    "PS_step_chosen = btn_PS_step.value\n",
    "PS_step_idx = int(btn_PS_step.index)\n",
    "emg_file_chosen = emg_files[PS_step_idx]\n",
    "vent_file_chosen = vent_files[PS_step_idx]\n",
    "print(\"The chosen files are:\\n\", emg_file_chosen, '\\n', vent_file_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EMG and ventilator data recordings from the selected folders.\n",
    "data_emg = Poly5Reader(emg_file_chosen)\n",
    "data_vent = Poly5Reader(vent_file_chosen)\n",
    "data_emg_samples = data_emg.samples[:data_emg.num_samples]\n",
    "fs_emg = data_emg.sample_rate\n",
    "data_vent_samples = data_vent.samples[:data_vent.num_samples]\n",
    "fs_vent = data_vent.sample_rate\n",
    "\n",
    "# Define the time series of the EMG and ventilator recordings\n",
    "y_emg = data_emg_samples\n",
    "# y_emg = data_emg_samples[:, :350*2048]\n",
    "# Reshufle the channels if necessary\n",
    "# y_emg = np.array([-data_emg_samples[0, :], \n",
    "#                    data_emg_samples[1, :], \n",
    "#                    data_emg_samples[2, :]])\n",
    "# # Reshufle the channels if necessary\n",
    "# y_emg = np.array([-data_emg_samples[2, :], \n",
    "#                    data_emg_samples[0, :], \n",
    "#                    -data_emg_samples[1, :]])\n",
    "y_vent = data_vent_samples\n",
    "\n",
    "# Define the time axes\n",
    "t_emg = np.array([i/fs_emg for i in range(len(y_emg[0, :]))])\n",
    "t_vent = np.array([i/fs_vent for i in range(len(y_vent[0, :]))])\n",
    "\n",
    "# Default settings for window of interest\n",
    "# manoeuvres (Pocc)\n",
    "# t_start_default = t_vent[-1]-61\n",
    "# t_end_default = t_vent[-1]-1\n",
    "t_start_default = t_vent[0]\n",
    "t_end_default = t_vent[-1]\n",
    "\n",
    "del data_emg_samples, data_vent_samples, data_emg, data_vent\n",
    "\n",
    "btn_plt_raw = widgets.Dropdown(\n",
    "    options=['Yes', 'No'],\n",
    "    value='No',\n",
    "    description='Plot raw data?',\n",
    "    parasabled=False,\n",
    ")\n",
    "display(btn_plt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data if wanted\n",
    "if btn_plt_raw.value == 'Yes':\n",
    " \n",
    "    fig, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    axis[0, 0].grid(True)\n",
    "    axis[0, 0].plot(t_emg, y_emg[0])\n",
    "    axis[0, 0].set(title='sEMG leads')\n",
    "    axis[0, 0].set_ylabel('ECG (uV)')\n",
    "\n",
    "    axis[1, 0].grid(True)\n",
    "    axis[1, 0].plot(t_emg, y_emg[1])\n",
    "    axis[1, 0].set_ylabel('sEMGdi (uV)')\n",
    "    axis[1, 0].set_xlabel('t (s)')\n",
    "\n",
    "    axis[2, 0].grid(True)\n",
    "    axis[2, 0].plot(t_emg, y_emg[2])\n",
    "    axis[2, 0].set_ylabel('sEMGpara (uV)')\n",
    "    axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "    axis[0, 1].set(title='Ventilator data')\n",
    "    axis[0, 1].grid(True)\n",
    "    axis[0, 1].plot(t_vent, y_vent[0])\n",
    "    axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "    axis[1, 1].grid(True)\n",
    "    axis[1, 1].plot(t_vent, y_vent[1])\n",
    "    axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "    axis[2, 1].grid(True)\n",
    "    axis[2, 1].plot(t_vent, y_vent[2])\n",
    "    axis[2, 1].set_ylabel('V (mL)')\n",
    "    axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select the time window of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = t_start_default\n",
    "end = t_end_default\n",
    "\n",
    "start_s = int(float(start)* fs_emg)\n",
    "end_s = min([int(float(end)*fs_emg), len(y_emg[0,:])-1])\n",
    "start_vent_s = int(float(start)* fs_vent)\n",
    "end_vent_s = min(\n",
    "    [int(float(end)* fs_vent), len(y_vent[0,:])-1]\n",
    ")\n",
    "\n",
    "fig_w = (int(end_vent_s)-int(start_vent_s))//(fs_vent*80)*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.a. ECG properties extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter raw EMG signals according to AHA 1990 guidelines\n",
    "y_emg_ECG_filt_AHA = filt.emg_bandpass_butter_sample(y_emg, 0.05, 150, fs_emg)\n",
    "\n",
    "y_emg_ECG_filt = filt.emg_bandpass_butter_sample(y_emg, 1, 80, fs_emg)\n",
    "# y_emg_ECG_filt = y_emg\n",
    "\n",
    "# # See https://ieeexplore.ieee.org/document/10290007 for performance\n",
    "# ecg_method = 'Zong'      # 'neurokit', 'hamilton2002', 'pantompkins1985', 'engzeemod2012'\n",
    "\n",
    "ecg_dicts = dict()\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    ecg_dicts[channel] = dict()\n",
    "\n",
    "# RMS and peak detection settings\n",
    "RMS_window_ecg_ms = 50\n",
    "RMS_windows_samp = int(RMS_window_ecg_ms / 1000 *  fs_emg)\n",
    "distance = 2048//4\n",
    "\n",
    "# Moving baseline parameters\n",
    "w_moving_baseline = 5 * fs_emg\n",
    "\n",
    "# ecg_type = 'raw'    # 'clean'\n",
    "channel = 'ecg'\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "T_ecg_bin_w = 0.1\n",
    "\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    y_emg_ECG_filt[idx, :]\n",
    "    ecg_dicts[channel]['raw'] = y_emg[idx, :]\n",
    "    ecg_dicts[channel]['filt'] = y_emg_ECG_filt[idx, :]\n",
    "    ecg_dicts[channel]['filt_AHA'] = y_emg_ECG_filt_AHA[idx, :]\n",
    "    \n",
    "    pre_samp = int(np.ceil(RMS_windows_samp/2))\n",
    "    post_samp = int(np.floor(RMS_windows_samp/2))\n",
    "    padding_pre = np.zeros((pre_samp,))\n",
    "    padding_end = np.zeros((post_samp,))\n",
    "    ecg_dicts[channel]['filt_padded'] = np.concatenate(\n",
    "         (padding_pre, ecg_dicts[channel]['filt'], padding_end))\n",
    "\n",
    "    # sEAdi_padded = evl.full_rolling_rms(emg_di_gated_padded, RMS_windows_samp)\n",
    "    # sEAdi = sEAdi_padded[:-RMS_windows_samp]\n",
    "\n",
    "    ecg_dicts[channel]['rms'] = evl.full_rolling_rms(\n",
    "        ecg_dicts[channel]['filt_padded'], \n",
    "        RMS_windows_samp)\n",
    "    \n",
    "    ecg_dicts[channel]['rms'] = ecg_dicts[channel]['rms'][:-RMS_windows_samp]\n",
    "    \n",
    "    prominence = 0.5*(np.percentile(ecg_dicts[channel]['rms'], 95) \n",
    "                  - min(ecg_dicts[channel]['rms']))\n",
    "    \n",
    "    peaks, _ = scipy.signal.find_peaks(ecg_dicts[channel]['rms'], \n",
    "                                       prominence=prominence,\n",
    "                                       distance=distance)\n",
    "    ecg_dicts[channel]['peaks'] = np.array(peaks)\n",
    "    ecg_dicts[channel]['method'] = 'custom'\n",
    "\n",
    "\n",
    "    bin_w = 0.05\n",
    "\n",
    "    T_peaks = (ecg_dicts[channel]['peaks'][1:]-ecg_dicts[channel]['peaks'][:-1])/fs_emg\n",
    "    hist, bin_edges = np.histogram(T_peaks, bins=[x*bin_w for x in \n",
    "                                                range(int(max(T_peaks)/bin_w))])\n",
    "    bin_edges = bin_edges[1:]\n",
    "    pks, _ = scipy.signal.find_peaks(hist, height=max(hist)*T_ecg_bin_w)\n",
    "\n",
    "\n",
    "    if len(pks) == 3:\n",
    "            # print(bin_edges[pks])\n",
    "\n",
    "            extra_pks = np.argwhere((T_peaks/bin_edges[pks[-1]] < 0.5) & (np.abs((T_peaks-bin_edges[pks[0]])/bin_edges[pks[0]]) < 0.5)) + 1\n",
    "            # print(extra_pks)\n",
    "    else:\n",
    "        extra_pks = []   \n",
    "\n",
    "    ecg_dicts[channel]['peaks'] = np.delete(ecg_dicts[channel]['peaks'], \n",
    "                                            extra_pks)\n",
    "    \n",
    "    T_peaks = (ecg_dicts[channel]['peaks'][1:]-ecg_dicts[channel]['peaks'][:-1])/fs_emg\n",
    "    # hist, bin_edges = np.histogram(T_peak, bins=[x*bin_w for x in \n",
    "    #                   range(int(max(T_peak)/bin_w))])\n",
    "    hist, bin_edges = np.histogram(T_peaks, bins=[x*bin_w for x in \n",
    "                      range(int(max(T_peaks)/bin_w))])\n",
    "    \n",
    "    bin_edges = bin_edges[1:]\n",
    "    pks, _ = scipy.signal.find_peaks(hist, height=max(hist)*T_ecg_bin_w)\n",
    "\n",
    "    if len(pks) > 1:\n",
    "         print('Warning: Non-QRS complexes included in channel: ' + channel)\n",
    "         print(T_peaks/bin_edges[pks[-1]])\n",
    "         print(np.abs((T_peaks-bin_edges[pks[0]])/bin_edges[pks[0]]))\n",
    "\n",
    "    ecg_dicts[channel]['mb_rms'] = moving_baseline(ecg_dicts[channel]['rms'], fs_emg, w_moving_baseline)\n",
    "    ecg_dicts[channel]['mb_filt'] = moving_baseline(ecg_dicts[channel]['filt'], fs_emg, w_moving_baseline)\n",
    "\n",
    "    # scipy.signal.argrelextrema(ecg_dicts[channel]['d_dt_mb_rms'])\n",
    "\n",
    "len(ecg_dicts['ecg']['peaks']), len(ecg_dicts['di']['peaks']), len(ecg_dicts['para']['peaks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_dicts[channel]['peak_upslope_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel in enumerate(channel_list):\n",
    "    ecg_dicts[channel]['d_dt_rms'] = (ecg_dicts[channel]['rms'][1:] - ecg_dicts[channel]['rms'][:-1])*fs_emg\n",
    "\n",
    "    local_extremes_vec_up = scipy.signal.argrelextrema(ecg_dicts[channel]['d_dt_rms'], np.greater, order=RMS_windows_samp//2)[0]\n",
    "    idxs_mat_up = (np.matlib.repmat(local_extremes_vec_up, len(ecg_dicts[channel]['peaks']), 1) \n",
    "                - np.matlib.repmat(ecg_dicts[channel]['peaks'], len(local_extremes_vec_up), 1).T)\n",
    "\n",
    "    loc_crossings_up = np.argwhere(np.diff(np.sign(idxs_mat_up)) != 0)\n",
    "    loc_crossings_up = loc_crossings_up[:, 1]\n",
    "\n",
    "    ecg_dicts[channel]['peak_upslope_idx'] = local_extremes_vec_up[loc_crossings_up]\n",
    "    ecg_dicts[channel]['peak_upslope_val'] = ecg_dicts[channel]['d_dt_rms'][ecg_dicts[channel]['peak_upslope_idx']]\n",
    "\n",
    "\n",
    "\n",
    "    local_extremes_vec_down = scipy.signal.argrelextrema(-ecg_dicts[channel]['d_dt_rms'], np.greater, order=RMS_windows_samp//2)[0]\n",
    "    idxs_mat_down = (np.matlib.repmat(local_extremes_vec_down, len(ecg_dicts[channel]['peaks']), 1) \n",
    "                - np.matlib.repmat(ecg_dicts[channel]['peaks'], len(local_extremes_vec_down), 1).T)\n",
    "\n",
    "    loc_crossings_down = np.argwhere(np.diff(np.sign(idxs_mat_down)) != 0)\n",
    "    loc_crossings_down = loc_crossings_down[:, 1] + 1\n",
    "\n",
    "    ecg_dicts[channel]['peak_downslope_idx'] = local_extremes_vec_down[loc_crossings_down]\n",
    "    ecg_dicts[channel]['peak_downslope_val'] = ecg_dicts[channel]['d_dt_rms'][ecg_dicts[channel]['peak_downslope_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = ecg_dicts[channel]['rms'][ecg_dicts[channel]['peak_upslope_idx']]\n",
    "dy_dt_vals = ecg_dicts[channel]['peak_upslope_val']\n",
    "\n",
    "ecg_dicts[channel]['peak_upslope_idx_ds'] = np.array(y_vals * fs_emg // (dy_dt_vals), dtype=int)\n",
    "\n",
    "ecg_dicts[channel]['peak_upslope_idx_ds'][\n",
    "    np.abs(ecg_dicts[channel]['peak_upslope_idx_ds'])\n",
    "    > (np.median(ecg_dicts[channel]['peaks'][1:]-ecg_dicts[channel]['peaks'][:-1]))] = 0\n",
    "ecg_dicts[channel]['peak_upslope_start_s'] = ecg_dicts[channel]['peak_upslope_idx'] - ecg_dicts[channel]['peak_upslope_idx_ds']\n",
    "\n",
    "channel, ecg_dicts[channel]['peaks'][:10]/fs_emg, y_vals[:10], dy_dt_vals[:10], ecg_dicts[channel]['peak_upslope_idx_ds'][:10], ecg_dicts[channel]['peak_upslope_start_s'][:10]/fs_emg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_hist_slopes, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6))\n",
    "\n",
    "\n",
    "# channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "# for idx, channel  in enumerate(channel_list):\n",
    "#     T_peaks = ecg_dicts[channel]['peak_downslope_val']\n",
    "#     bin_w = np.max(T_peaks)/100\n",
    "\n",
    "#     hist, bin_edges = np.histogram(T_peaks, bins=[x*bin_w for x in \n",
    "#                       range(int(max(T_peaks)/bin_w))])\n",
    "#     bin_edges = bin_edges[1:]\n",
    "#     pks, _ = scipy.signal.find_peaks(hist, height=max(hist)/10)\n",
    "\n",
    "#     axis[idx].plot(bin_edges,hist)\n",
    "#     axis[idx].plot(bin_edges[pks],hist[pks], 'rx')\n",
    "#     axis[idx].set_title(channel)\n",
    "#     axis[idx].set_xlabel('dRMS/dt (uV/s)')\n",
    "\n",
    "# axis[0].set_ylabel('Bin count (.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel in enumerate(channel_list):   \n",
    "    y_vals = ecg_dicts[channel]['rms'][ecg_dicts[channel]['peak_upslope_idx']]\n",
    "    dy_dt_vals = ecg_dicts[channel]['peak_upslope_val']\n",
    "\n",
    "    ecg_dicts[channel]['peak_upslope_idx_ds'] = np.array(y_vals * fs_emg // (dy_dt_vals), dtype=int).astype(np.int64)\n",
    "\n",
    "    ecg_dicts[channel]['peak_upslope_idx_ds'][\n",
    "        np.abs(ecg_dicts[channel]['peak_upslope_idx_ds'])\n",
    "        > 2*(np.median(ecg_dicts[channel]['peaks'][1:]-ecg_dicts[channel]['peaks'][:-1]))] = 0\n",
    "    ecg_dicts[channel]['peak_upslope_start_s'] = ecg_dicts[channel]['peak_upslope_idx'] - ecg_dicts[channel]['peak_upslope_idx_ds']\n",
    "\n",
    "    y_vals = ecg_dicts[channel]['rms'][ecg_dicts[channel]['peak_downslope_idx']]\n",
    "    dy_dt_vals = ecg_dicts[channel]['peak_downslope_val']\n",
    "\n",
    "    ecg_dicts[channel]['peak_downslope_idx_ds'] = np.array(y_vals * fs_emg // (dy_dt_vals), dtype=int).astype(np.int64)\n",
    "    ecg_dicts[channel]['peak_downslope_idx_ds'][\n",
    "        np.abs(ecg_dicts[channel]['peak_downslope_idx_ds'])\n",
    "        > 2*(np.median(ecg_dicts[channel]['peaks'][1:]-ecg_dicts[channel]['peaks'][:-1]))] = 0\n",
    "    ecg_dicts[channel]['peak_downslope_end_s'] = ecg_dicts[channel]['peak_downslope_idx'] - ecg_dicts[channel]['peak_downslope_idx_ds']\n",
    "\n",
    "\n",
    "    # while np.min(ecg_dicts[channel]['peak_upslope_start_s']) < 0:\n",
    "    #     ecg_dicts[channel]['peaks'] = np.delete(ecg_dicts[channel]['peaks'], 0)\n",
    "    #     ecg_dicts[channel]['peak_upslope_idx'] = np.delete(ecg_dicts[channel]['peak_upslope_idx'], 0)\n",
    "    #     ecg_dicts[channel]['peak_upslope_val'] = np.delete(ecg_dicts[channel]['peak_upslope_val'], 0)\n",
    "    #     ecg_dicts[channel]['peak_upslope_idx_ds'] = np.delete(ecg_dicts[channel]['peak_upslope_idx_ds'], 0)\n",
    "    #     ecg_dicts[channel]['peak_upslope_start_s'] = np.delete(ecg_dicts[channel]['peak_upslope_start_s'], 0)\n",
    "    #     ecg_dicts[channel]['peak_downslope_idx'] = np.delete(ecg_dicts[channel]['peak_upslope_idx'], 0)\n",
    "    #     ecg_dicts[channel]['peak_downslope_val'] = np.delete(ecg_dicts[channel]['peak_upslope_val'], 0)\n",
    "    #     ecg_dicts[channel]['peak_downslope_idx_ds'] = np.delete(ecg_dicts[channel]['peak_upslope_idx_ds'], 0)\n",
    "    #     ecg_dicts[channel]['peak_downslope_start_s'] = np.delete(ecg_dicts[channel]['peak_upslope_start_s'], 0)\n",
    "\n",
    "    # while np.max(ecg_dicts[channel]['peak_downslope_end_s']) >= len(ecg_dicts[channel]['rms']):\n",
    "    #     ecg_dicts[channel]['peaks'] = np.delete(ecg_dicts[channel]['peaks'], -1)\n",
    "    #     ecg_dicts[channel]['peak_upslope_idx'] = np.delete(ecg_dicts[channel]['peak_upslope_idx'], -1)\n",
    "    #     ecg_dicts[channel]['peak_upslope_val'] = np.delete(ecg_dicts[channel]['peak_upslope_val'], -1)\n",
    "    #     ecg_dicts[channel]['peak_upslope_idx_ds'] = np.delete(ecg_dicts[channel]['peak_upslope_idx_ds'], -1)\n",
    "    #     ecg_dicts[channel]['peak_upslope_start_s'] = np.delete(ecg_dicts[channel]['peak_upslope_start_s'], -1)\n",
    "    #     ecg_dicts[channel]['peak_downslope_idx'] = np.delete(ecg_dicts[channel]['peak_upslope_idx'], -1)\n",
    "    #     ecg_dicts[channel]['peak_downslope_val'] = np.delete(ecg_dicts[channel]['peak_upslope_val'], -1)\n",
    "    #     ecg_dicts[channel]['peak_downslope_idx_ds'] = np.delete(ecg_dicts[channel]['peak_upslope_idx_ds'], -1)\n",
    "    #     ecg_dicts[channel]['peak_downslope_start_s'] = np.delete(ecg_dicts[channel]['peak_upslope_start_s'], -1)\n",
    "\n",
    "    # print(y_vals[:10], dy_dt_vals[:10], fs_emg * y_vals[:10]//dy_dt_vals[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin_edges[1:], hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    axis[idx, 0].grid(True)\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['raw'] - np.percentile(ecg_dicts[channel]['raw'], 5))\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'])\n",
    "    # axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_filt'])\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_rms'])\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['rms'])\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peak_upslope_idx']], ecg_dicts[channel]['rms'][ecg_dicts[channel]['peak_upslope_idx']], 'rx')\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peak_downslope_idx']], ecg_dicts[channel]['rms'][ecg_dicts[channel]['peak_downslope_idx']], 'rx')\n",
    "\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peak_upslope_idx']], ecg_dicts[channel]['filt'][ecg_dicts[channel]['peak_upslope_idx']], 'cx')\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peak_downslope_idx']], ecg_dicts[channel]['filt'][ecg_dicts[channel]['peak_downslope_idx']], 'cx')\n",
    "\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peak_upslope_start_s']], ecg_dicts[channel]['filt'][ecg_dicts[channel]['peak_upslope_start_s']], 'mx')\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peak_downslope_end_s']], ecg_dicts[channel]['filt'][ecg_dicts[channel]['peak_downslope_end_s']], 'kx')\n",
    "\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peaks']], \n",
    "                      ecg_dicts[channel]['rms'][ecg_dicts[channel]['peaks']], '*r')\n",
    "    # if idx == 0:\n",
    "    #     axis[idx, 0].plot(t_emg[ecg_dicts[channel]['peaks'][extra_pks]], \n",
    "    #                     ecg_dicts[channel]['rms'][ecg_dicts[channel]['peaks'][extra_pks]], 'xc')\n",
    "    \n",
    "    extra_pks\n",
    "    \n",
    "    axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 0].set(title='sEMG leads')\n",
    "axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 1].set(title='Ventilator data')\n",
    "axis[0, 1].grid(True)\n",
    "axis[0, 1].plot(t_vent, y_vent[0])\n",
    "axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "axis[1, 1].grid(True)\n",
    "axis[1, 1].plot(t_vent, y_vent[1])\n",
    "axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "axis[2, 1].grid(True)\n",
    "axis[2, 1].plot(t_vent, y_vent[2])\n",
    "axis[2, 1].set_ylabel('V (mL)')\n",
    "axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(ecg_dicts[channel]['peak_upslope_start_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1121616\n",
    "150086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hist_ecg, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6))\n",
    "bin_w = 0.05\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    T_peaks = (ecg_dicts[channel]['peaks'][1:]\n",
    "               -ecg_dicts[channel]['peaks'][:-1])/fs_emg\n",
    "\n",
    "    hist, bin_edges = np.histogram(T_peaks, bins=[x*bin_w for x in \n",
    "                      range(int(max(T_peaks)/bin_w))])\n",
    "    bin_edges = bin_edges[1:]\n",
    "    pks, _ = scipy.signal.find_peaks(hist, height=max(hist)/10)\n",
    "\n",
    "    axis[idx].plot(bin_edges,hist)\n",
    "    axis[idx].plot(bin_edges[pks],hist[pks], 'rx')\n",
    "    axis[idx].set_title(channel)\n",
    "    axis[idx].set_xlabel('Tpeak (s)')\n",
    "\n",
    "axis[0].set_ylabel('Bin count (.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max amplitude\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    ecg_dicts[channel]['mins'] = []\n",
    "    ecg_dicts[channel]['min_idxs'] = []\n",
    "    ecg_dicts[channel]['maxs'] = []\n",
    "    ecg_dicts[channel]['max_idxs'] = []\n",
    "    ecg_dicts[channel]['minmax'] = []\n",
    "\n",
    "    ecg_dicts[channel]['peaks']\n",
    "    win_half = int(np.median(ecg_dicts[channel]['peaks'][1:] \n",
    "                             - ecg_dicts[channel]['peaks'][:-1])//10)\n",
    "    for pk_idx, R_peak  in enumerate(ecg_dicts[channel]['peaks']):\n",
    "        _s_start = max([0, R_peak-win_half])\n",
    "        _s_end = min([len(ecg_dicts[channel]['raw']), R_peak+win_half])\n",
    "        # _signal = ecg_dicts[channel]['filt_AHA'][_s_start:_s_end]\n",
    "        _signal = ecg_dicts[channel]['filt'][_s_start:_s_end]\n",
    "\n",
    "        ecg_dicts[channel]['mins'].append(np.min(_signal))\n",
    "        ecg_dicts[channel]['min_idxs'].append(\n",
    "            np.argmin(_signal) + R_peak - win_half)\n",
    "        ecg_dicts[channel]['maxs'].append(np.max(_signal))\n",
    "        ecg_dicts[channel]['max_idxs'].append(\n",
    "            np.argmax(_signal) + R_peak - win_half)\n",
    "        ecg_dicts[channel]['minmax'].append(np.max(_signal) - np.min(_signal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    axis[idx, 0].grid(True)\n",
    "    # axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt_AHA'])\n",
    "    # axis[idx, 0].plot(t_emg[ecg_dicts[channel]['min_idxs']], \n",
    "    #                   ecg_dicts[channel]['filt_AHA'][ecg_dicts[channel]['min_idxs']], '*r')\n",
    "    # axis[idx, 0].plot(t_emg[ecg_dicts[channel]['max_idxs']], \n",
    "    #                   ecg_dicts[channel]['filt_AHA'][ecg_dicts[channel]['max_idxs']], '*g')\n",
    "    \n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'])\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['min_idxs']], \n",
    "                      ecg_dicts[channel]['filt'][ecg_dicts[channel]['min_idxs']], '*r')\n",
    "    axis[idx, 0].plot(t_emg[ecg_dicts[channel]['max_idxs']], \n",
    "                      ecg_dicts[channel]['filt'][ecg_dicts[channel]['max_idxs']], '*g')\n",
    "\n",
    "    axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "\n",
    "axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 0].set(title='sEMG leads')\n",
    "axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 1].set(title='Ventilator data')\n",
    "axis[0, 1].grid(True)\n",
    "axis[0, 1].plot(t_vent, y_vent[0])\n",
    "axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "axis[1, 1].grid(True)\n",
    "axis[1, 1].plot(t_vent, y_vent[1])\n",
    "axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "axis[2, 1].grid(True)\n",
    "axis[2, 1].plot(t_vent, y_vent[2])\n",
    "axis[2, 1].set_ylabel('V (mL)')\n",
    "axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of QRS min-max amplitudes\n",
    "\n",
    "fig_hist, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6))\n",
    "bin_w = 5\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    axis[idx].hist(ecg_dicts[channel]['minmax'], \n",
    "                bins=[x*bin_w for x in range(int(max(ecg_dicts[channel]['minmax'])/bin_w))])\n",
    "    axis[idx].set_title(channel)\n",
    "    axis[idx].set_xlabel('QRS min-max amp (uV)')\n",
    "    \n",
    "    axis[idx].set_xlim([np.percentile(ecg_dicts[channel]['minmax'], 1), np.percentile(ecg_dicts[channel]['minmax'], 99)])\n",
    "\n",
    "axis[0].set_ylabel('Bin count (.)')\n",
    "\n",
    "(np.median(ecg_dicts['ecg']['minmax']), np.median(ecg_dicts['di']['minmax']), \n",
    " np.median(ecg_dicts['para']['minmax']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Add the outcome data to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient + ' / ' + measurement_date + ' / ' + PS_step_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t.savefig(main_output_dir + '/' + patient + '/' + measurement_date\n",
    "              + '/' + measurement_date + '_' + patient + '_' \n",
    "              + PS_step_chosen + 'ECG_timeplots.png', \n",
    "              dpi=300)\n",
    "fig_hist.savefig(main_output_dir + '/' + patient + '/' + measurement_date\n",
    "              + '/' + measurement_date + '_' + patient + '_' \n",
    "              + PS_step_chosen + 'ECG_histograms.png', \n",
    "              dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# di_data_list = []\n",
    "# para_data_list = []\n",
    "# Paw_data_list = []\n",
    "# Vvent_data_list = []\n",
    "# ecg_data_list = []\n",
    "\n",
    "# ecg_data_all_dict = dict()\n",
    "# df_ecg_all_dict = dict()\n",
    "# channel_list = ['ecg', 'di', 'para']\n",
    "# columns_ecg_all = ['patient', 'measurement',\n",
    "#               'ecg_minmax', 'ecg_min', 'ecg_max', 'ecg_method']\n",
    "# for idx, channel  in enumerate(channel_list):\n",
    "#     ecg_data_all_dict[channel] = []\n",
    "#     df_ecg_all_dict[channel] = pd.DataFrame(ecg_data_all_dict[channel], columns=columns_ecg_all)\n",
    "\n",
    "# # PS_step_del = '002'\n",
    "# PS_step_del = PS_step_chosen\n",
    "# df_di = df_di.drop(df_di[df_di['measurement'] == PS_step_del].index)\n",
    "# df_para = df_para.drop(df_para[df_para['measurement'] == PS_step_del].index)\n",
    "# df_Paw = df_Paw.drop(df_Paw[df_Paw['measurement'] == PS_step_del].index)\n",
    "# df_Vvent = df_Vvent.drop(df_Vvent[df_Vvent['measurement'] == PS_step_del].index)\n",
    "# df_ecg = df_ecg.drop(df_ecg[df_ecg['measurement'] == PS_step_del].index)\n",
    "\n",
    "# di_data_list = list(df_di.values)W\n",
    "# para_data_list = list(df_para.values)\n",
    "# Paw_data_list = list(df_Paw.values)\n",
    "# Vvent_data_list = list(df_Vvent.values)\n",
    "\n",
    "# df_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store overall ECG parameters in a dataframe (~ table)\n",
    "columns_ecg = ['patient', 'measurement',\n",
    "              'ecg_ecg_minmax', 'ecg_method', \n",
    "              'ecg_di_minmax', 'di_method', \n",
    "              'ecg_para_minmax', 'para_method']\n",
    "\n",
    "df_ecg = pd.DataFrame(ecg_data_list, columns=columns_ecg)\n",
    "\n",
    "if len(df_ecg[df_ecg['measurement'] == PS_step_chosen]) == 0:\n",
    "    data_ecg_tmp = [patient, PS_step_chosen,\n",
    "                    np.median(ecg_dicts['ecg']['minmax']), \n",
    "                    ecg_dicts['ecg']['method'], \n",
    "                    np.median(ecg_dicts['di']['minmax']), \n",
    "                    ecg_dicts['di']['method'], \n",
    "                    np.median(ecg_dicts['para']['minmax']),\n",
    "                    ecg_dicts['para']['method'], \n",
    "                ]\n",
    "    \n",
    "    ecg_data_list.append(data_ecg_tmp)\n",
    "    \n",
    "    df_ecg = pd.DataFrame(ecg_data_list, columns=columns_ecg)\n",
    "else:\n",
    "    print('Data of PS step ' + PS_step_chosen + ' already added to the ' \n",
    "          + 'dataframe. Don''t add the data twice!')\n",
    "    \n",
    "df_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all ECG peaks in a in a dataframe (~ table)\n",
    "columns_ecg_all = ['patient', 'measurement',\n",
    "                   'ecg_min', 'ecg_max', 'ecg_minmax', 'ecg_method']\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "for _, channel  in enumerate(channel_list):\n",
    "    if len(df_ecg_all_dict[channel][df_ecg_all_dict[channel]['measurement'] == PS_step_chosen]) == 0:\n",
    "        for idx in range(len(ecg_dicts[channel]['minmax'])):\n",
    "            data_ecg_all_tmp = [patient, PS_step_chosen,\n",
    "                                ecg_dicts[channel]['mins'][idx],\n",
    "                                ecg_dicts[channel]['maxs'][idx],\n",
    "                                ecg_dicts[channel]['minmax'][idx],\n",
    "                                ecg_dicts[channel]['method']]\n",
    "        \n",
    "            ecg_data_all_dict[channel].append(data_ecg_all_tmp)\n",
    "            \n",
    "        df_ecg_all_dict[channel] = pd.DataFrame(ecg_data_all_dict[channel], columns=columns_ecg_all)\n",
    "    else:\n",
    "        print('Data of PS step ' + PS_step_chosen + ' already added to the ' \n",
    "            + 'dataframe for channel ' +  channel + '. Don''t add the data '\n",
    "            + 'twice!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move on to the next measurement\n",
    "if PS_step_chosen in df_ecg['measurement'].to_list():\n",
    "    if PS_step_idx >= 5:\n",
    "        print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. You can continue to the '\n",
    "              + 'saving the overall data!')\n",
    "              \n",
    "    elif PS_step_chosen != list_of_numbers_string[PS_step_idx]:\n",
    "        print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. Run the next PEEP step, '\n",
    "              + 'starting at step 2C.')\n",
    "    else:\n",
    "        PS_step_idx += 1\n",
    "        if PS_step_idx >= 5:\n",
    "            print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. You can continue to the '\n",
    "              + 'saving the overall data!')\n",
    "        else:\n",
    "            print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. Run the next PEEP step, '\n",
    "              + 'starting at step 2C.')\n",
    "else:\n",
    "    print('Data of measurement ' + PS_step_chosen + ' not yet added to the ' \n",
    "        + 'dataframe!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['To next PS step'](#section_ps_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store session data if complete\n",
    "if ((len(set(df_ecg['measurement'].values)) < 5) |\n",
    "    (measurement_date != measurement_dates[date_idx])):\n",
    "    print('Warning: Not 5 PS settings evaluated yet!')\n",
    "else:\n",
    "    df_ecg.to_csv(main_output_dir + '/' + patient + '/' + measurement_date  \n",
    "              + '/' + measurement_date + '_' + patient\n",
    "              +'_ECGs.csv')\n",
    "    \n",
    "    for _, channel in enumerate(channel_list):\n",
    "   \n",
    "        df_ecg_all_dict[channel].to_csv(main_output_dir + '/' + patient + '/' \n",
    "              + measurement_date + '/' + measurement_date + '_' + patient\n",
    "              +'_ECGall_' + channel + '.csv')\n",
    "    \n",
    "    print('Notification: Data of 5 PS settings stored!')\n",
    "    print(measurement_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move on to the next measurement date if data saved\n",
    "\n",
    "if not os.path.exists(main_output_dir + '/' + patient + '/' + measurement_date  \n",
    "                      + '/' + measurement_date + '_' + patient \n",
    "                      +'_ECGall_para' + '.csv'):\n",
    "    print('Warning: Data not stored! Do not progress to next date!')\n",
    "elif ((len(set(df_ecg_all_dict['para']['measurement'].values)) < 5) \n",
    "      |((date_idx < len(measurement_dates)\n",
    "         and (measurement_date != measurement_dates[date_idx])))\n",
    "         ):\n",
    "    print('Warning: Data not stored! Do not progress to next date!')\n",
    "else:\n",
    "    if date_idx < len(measurement_dates)-1:\n",
    "        print('Notification: Data appropriately stored. '\n",
    "              +'You may progress to next date:')\n",
    "        \n",
    "        if measurement_date == measurement_dates[date_idx]:\n",
    "            date_idx += 1            \n",
    "            print(measurement_dates[date_idx])\n",
    "    else:\n",
    "        if patient == patients[patient_idx]:\n",
    "            patient_idx += 1\n",
    "            date_idx = 0\n",
    "        print('Notification: Data appropriately stored. \\n'+\n",
    "              'This was the last measurement of this patient. '\n",
    "              +'You may progress to next patient!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data anyway:\n",
    "# df_ecg.to_csv(main_output_dir + '/' + patient + '/' + measurement_date  \n",
    "#             + '/' + measurement_date + '_' + patient\n",
    "#             +'_ECGs.csv')\n",
    "\n",
    "# for _, channel in enumerate(channel_list):\n",
    "\n",
    "#     df_ecg_all_dict[channel].to_csv(main_output_dir + '/' + patient + '/' \n",
    "#             + measurement_date + '/' + measurement_date + '_' + patient\n",
    "#             +'_ECGall_' + channel + '.csv')\n",
    "\n",
    "# date_idx += 1\n",
    "# if date_idx < len(measurement_dates):\n",
    "#     print('Notification: Data appropriately stored. '\n",
    "#             +'You may progress to next date!')\n",
    "#     print(measurement_date)\n",
    "# else:\n",
    "#     if patient == patients[patient_idx]:\n",
    "#         patient_idx += 1\n",
    "#         date_idx = 0\n",
    "#     print('Notification: Data appropriately stored. \\n'+\n",
    "#             'This was the last measurement of this patient. '\n",
    "#             +'You may progress to next patient!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move on to the next measurement date\n",
    "# date_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move on to the previous measurement date\n",
    "# date_idx -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['To next measurement date'](#section_date_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move on to the next patient\n",
    "# patient_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move on to the previous patient\n",
    "# patient_idx -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['To next patient'](#section_patient_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_twice = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation of ETPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalise the ETPdi, PTPocc and NMCdi values relative to PEEP = 9 cmH2O:\n",
    "# PEEP_norm = 9\n",
    "# if len(set(df.loc[df['PEEP_set'] == PEEP_norm, 'PEEP_set'].values)) != 1:\n",
    "#     print('Warning: PEEP = ', PEEP_norm, ' cmH2O is not available yet. ',\n",
    "#           'Run that dataset first!')\n",
    "# else:\n",
    "#     # Strict\n",
    "#     PTP_PEEP9_strict = np.median(output_df.loc[\n",
    "#         quality_df_bool_strict.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'PTP_occs']\n",
    "#     )\n",
    "#     ETP_PEEP9_strict = np.median(output_df.loc[\n",
    "#         quality_df_bool_strict.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'ETP_di_occs']\n",
    "#     )\n",
    "#     output_df = output_df.assign(PTP_norm_strict=\n",
    "#                      output_df['PTP_occs'] / PTP_PEEP9_strict)\n",
    "#     output_df = output_df.assign(ETP_norm_strict=\n",
    "#                      output_df['ETP_di_occs'] / ETP_PEEP9_strict)\n",
    "#     output_df = output_df.assign(NMC_di_norm_strict=\n",
    "#                      output_df['PTP_norm_strict'] / \n",
    "#                      output_df['ETP_norm_strict'])\n",
    "#     # Tolerant\n",
    "#     PTP_PEEP9_tolerant = np.median(output_df.loc[\n",
    "#         quality_df_bool_tolerant.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'PTP_occs']\n",
    "#     )\n",
    "#     ETP_PEEP9_tolerant = np.median(output_df.loc[\n",
    "#         quality_df_bool_tolerant.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'ETP_di_occs']\n",
    "#     )\n",
    "#     output_df = output_df.assign(PTP_norm_tol=\n",
    "#                      output_df['PTP_occs'] / PTP_PEEP9_tolerant)\n",
    "#     output_df = output_df.assign(ETP_norm_tol=\n",
    "#                      output_df['ETP_di_occs'] / ETP_PEEP9_tolerant)\n",
    "#     output_df = output_df.assign(NMC_di_norm_tol=\n",
    "#                      output_df['PTP_norm_tol'] / output_df['ETP_norm_tol'])\n",
    "\n",
    "# print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the normalised NMCdi values, permissible according to the tolerant \n",
    "# # criteria\n",
    "# if len(set(df['PS_set'].values)) < 4:\n",
    "#     print('Warning: Not 4 PS settings evaluated yet!')\n",
    "# else:\n",
    "#     passed_all_tolerant_crit = quality_df_bool_strict.all(axis=1)\n",
    "\n",
    "#     bp = output_df[passed_all_tolerant_crit].plot.scatter('PEEP_set', \n",
    "#                                                    'NMC_di_norm_strict')\n",
    "#     bp.set_ylabel('Normalised NMC_di (.)')\n",
    "#     bp.set_xlabel('PEEP (cmH2O)')\n",
    "#     bp.set_title('Normalised')\n",
    "#     ylims = bp.set_ylim()\n",
    "#     bp.set_ylim((0, ylims[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "715559eda0e456e9cdc499f5ec9b632cad73616ca8207bb3c3108e6214e21bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
