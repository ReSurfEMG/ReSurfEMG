{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the effects of PS on P, TV, F, sEAdi etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-me\n",
    "<!-- TODO ... Insert description ... -->\n",
    "\n",
    "The code to consecutively:\n",
    "<!-- TODO  Update code steps-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import code libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard code libraries\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy\n",
    "from scipy import interpolate as interp\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "import neurokit2 as nk\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code libraries from the ReSurfEMG repository\n",
    "# It uses the ReSurfEMG library version v0.2.1\n",
    "\n",
    "import resurfemg.preprocessing.ecg_removal as ecg_rm\n",
    "import resurfemg.preprocessing.envelope as evl\n",
    "import resurfemg.preprocessing.filtering as filt\n",
    "import resurfemg.postprocessing.features as feat\n",
    "\n",
    "from resurfemg.data_connector.tmsisdk_lite import Poly5Reader\n",
    "\n",
    "from resurfemg.config.config import Config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_baseline(signal, fs, window_length):\n",
    "    #  Augmented moving baseline for EMGdi signals for baseline crossing detection\n",
    "\n",
    "    # 2.a. Calculate the \"default\" moving baseline over the sEAdi data over a 7.5s \n",
    "    #     window\n",
    "    rolling_baseline = np.zeros((len(signal), ))\n",
    "    for idx in range(0, len(signal), int(fs/5)):\n",
    "        start_i = max([0, idx-int(window_length/2)])\n",
    "        end_i = min([len(signal), idx+int(window_length/2)])\n",
    "        baseline_value = np.nanpercentile(signal[start_i:end_i], 33)\n",
    "        \n",
    "        for i in range(idx, min([idx+int(fs/5), len(signal)])):\n",
    "            rolling_baseline[i] = baseline_value\n",
    "    \n",
    "    return rolling_baseline\n",
    "\n",
    "def augmented_moving_baseline(signal, fs, window_length, augmented_perc):\n",
    "    # 2.a. Calculate the \"default\" moving baseline over the sEAdi data over \n",
    "    #       a 7.5s window\n",
    "    default_rolling_baseline = moving_baseline(signal, fs, window_length)\n",
    "\n",
    "    # 2.b. Rolling standard deviation and mean over 7.5s window\n",
    "    baseline_series = pd.Series(default_rolling_baseline)\n",
    "    baseline_std = baseline_series.rolling(window_length, \n",
    "                                    min_periods=1, \n",
    "                                    center=True).std().values\n",
    "    baseline_mean = baseline_series.rolling(window_length, \n",
    "                                    min_periods=1, \n",
    "                                    center=True).mean().values\n",
    "\n",
    "    # 2.c. Augmented signal: EMG + abs([dEMG/dt]_smoothed)\n",
    "    ma_window = fs//2\n",
    "    # augmented_perc = 25\n",
    "    perc_window = fs\n",
    "\n",
    "    s = pd.Series(signal - default_rolling_baseline)\n",
    "    s_MA = s.rolling(window=ma_window, center=True).mean().values\n",
    "    ds_dt = (s_MA[1:] - s_MA[:-1] ) * fs\n",
    "    s_aug = signal[:-1] + np.abs(ds_dt)\n",
    "\n",
    "    # 2.d. Run the moving median filter over the augmented signal to obtain the \n",
    "    #       baseline\n",
    "    s_aug_rolling_baseline = np.zeros(\n",
    "        (len(signal)-1, ))\n",
    "\n",
    "    for idx in range(0, int(len(signal)-1), perc_window):\n",
    "        start_i = max([0, idx-int(window_length)])\n",
    "        end_i = min([len(signal)-1, idx+int(window_length)])\n",
    "\n",
    "        baseline_value = np.nanpercentile(\n",
    "            s_aug[start_i:end_i], augmented_perc)\n",
    "        \n",
    "        for i in range(idx, min([idx+int(perc_window), len(signal)-1])):\n",
    "            s_aug_rolling_baseline[i] = 1.2 * baseline_value\n",
    "    \n",
    "    return s_aug_rolling_baseline, baseline_std, baseline_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation of output folder for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data path - The main directory where all data is loaded from\n",
    "root_patient_data_directory = \\\n",
    "    config.get_directory('root_patient_data_directory')\n",
    "\n",
    "# Output data - General path to dir for saving .csvs and plots\n",
    "main_output_dir = os.path.join(config.get_directory('preprocessed'),\n",
    "                    '2024-05_PS_exploration_AUC_vec_ECG')\n",
    "\n",
    "if not os.path.exists(main_output_dir):\n",
    "    os.makedirs(main_output_dir)\n",
    "\n",
    "patient_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the ventilator and sEMG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a Select a patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the patient of interest\n",
    "# Expected data structure:\n",
    "# - Patient_01\n",
    "# -- Measurement_date_XXXX_XX_01\n",
    "# --- 001_Baseline\n",
    "# --- 002_PS_step_01\n",
    "# --- 003_PS_step_02\n",
    "# --- 004_PS_step_03\n",
    "# --- 005_PS_step_04\n",
    "# -- Measurement_date_XXXX_XX_03\n",
    "# --- 001_Baseline\n",
    "# --- 002_PS_step_01\n",
    "# --- 003_PS_step_02\n",
    "# --- 004_PS_step_03\n",
    "# --- 005_PS_step_04\n",
    "# -- Patient_02\n",
    "# -- Measurement_date_XXXX_XX_01\n",
    "# etc.\n",
    "\n",
    "# NB Run this cell once per patient!\n",
    "\n",
    "patient_folders = glob.glob(\n",
    "        os.path.join(root_patient_data_directory, '**',''), \n",
    "        recursive=False)\n",
    "\n",
    "patients = []\n",
    "for folder in patient_folders:\n",
    "    name = Path(folder).parts[-1]\n",
    "    patients.append(name)\n",
    "\n",
    "patients.sort()\n",
    "\n",
    "btn_pt = widgets.Dropdown(  \n",
    "    options=patients,\n",
    "    value=patients[patient_idx],\n",
    "    description='Select patient:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "date_idx = 0\n",
    "\n",
    "display(btn_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b Select a measurement date, or PS trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the day (PS trial) of interest for the selected patient\n",
    "# measurement_date ~ PEEP-trial\n",
    " \n",
    "# NB Run this cell once per patient/PEEP trial combination\n",
    "\n",
    "patient = btn_pt.value\n",
    "patient_idx =btn_pt.index\n",
    "\n",
    "measurement_folders = glob.glob(\n",
    "    os.path.join(root_patient_data_directory, patient, '**',''),\n",
    "    recursive=False)\n",
    "measurement_dates = []\n",
    "\n",
    "for folder in measurement_folders:\n",
    "    name = Path(folder).parts[-1]\n",
    "    measurement_dates.append(name)\n",
    "\n",
    "measurement_dates.sort()\n",
    "\n",
    "# Initialise the analysis: empty the output parameter list and start at the \n",
    "# baseline measurement (index 0)\n",
    "di_data_list = []\n",
    "para_data_list = []\n",
    "Paw_data_list = []\n",
    "Vvent_data_list =[]\n",
    "ecg_data_list = []\n",
    "\n",
    "ecg_data_all_dict = dict()\n",
    "df_ecg_all_dict = dict()\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "columns_ecg_all = ['patient', 'measurement',\n",
    "              'ecg_minmax', 'ecg_min', 'ecg_max', 'ecg_method']\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    ecg_data_all_dict[channel] = []\n",
    "    df_ecg_all_dict[channel] = pd.DataFrame(ecg_data_all_dict[channel], columns=columns_ecg_all)\n",
    "\n",
    "PS_step_idx = 0\n",
    "plt.close('all')\n",
    "\n",
    "# Set the default pipeline parameters\n",
    "# Gating settings\n",
    "gate_width_default = 0.10\n",
    "gate_threshold_default = 0.30\n",
    "gate_ECG_shift_default = -10\n",
    "gate_twice = False\n",
    "\n",
    "# RMS window\n",
    "RMS_window_ms_default = 200\n",
    "\n",
    "# Peak detection settings\n",
    "time_shift_default = 0.5 - RMS_window_ms_default/1000/2\n",
    "sEAdi_prominence_factor_default = 0.5\n",
    "sEApara_prominence_factor_default = 0.5\n",
    "\n",
    "btn_measurement = widgets.Dropdown(\n",
    "    options=measurement_dates,\n",
    "    value=measurement_dates[date_idx],\n",
    "    description='Select measurement date:',\n",
    "    parasabled=False,\n",
    ")\n",
    "display(btn_measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.c Select a PS step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the PS step of interest for the selected patient/measurement_date\n",
    "\n",
    "# NB Re-run this cell for each new PEEP trial, as it also empties output \n",
    "# parameter list (di_data_list)!\n",
    "\n",
    "\n",
    "# Create output data folders\n",
    "measurement_date = btn_measurement.value\n",
    "date_idx = btn_measurement.index\n",
    "\n",
    "output_path = os.path.join(main_output_dir, patient, measurement_date)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Identify all PS step folders:\n",
    "root_emg_directory = os.path.join(\n",
    "    root_patient_data_directory, patient, measurement_date)\n",
    "\n",
    "emg_pattern = os.path.join(root_emg_directory, '**/*.Poly5')\n",
    "emg_and_vent_files = glob.glob(emg_pattern, recursive=True)\n",
    "\n",
    "emg_files = []\n",
    "vent_files = []\n",
    "plt.close('all')\n",
    "\n",
    "for file in emg_and_vent_files:\n",
    "    if 'Draeger' in file:\n",
    "        vent_files.append(file)\n",
    "    else:\n",
    "        emg_files.append(file)\n",
    "\n",
    "emg_files.sort()\n",
    "vent_files.sort()\n",
    "\n",
    "list_of_numbers_string = []\n",
    "\n",
    "for i in range(len(emg_files)):\n",
    "    list_of_numbers_string.append(Path(emg_files[i]).parts[-2])\n",
    "\n",
    "# Select the PEEP step of interest. The selection menu initialises at the third \n",
    "# but last (index -4) recording. The PEEP steps are named after the folders \n",
    "# containing the data files (.poly5) of interest.\n",
    "\n",
    "btn_PS_step = widgets.Dropdown(\n",
    "    options=list_of_numbers_string,\n",
    "    value= list_of_numbers_string[PS_step_idx],\n",
    "    description='Picked File:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(btn_PS_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process selected option: the PEEP step of interest  \n",
    "PS_step_chosen = btn_PS_step.value\n",
    "PS_step_idx = int(btn_PS_step.index)\n",
    "emg_file_chosen = emg_files[PS_step_idx]\n",
    "vent_file_chosen = vent_files[PS_step_idx]\n",
    "print(\"The chosen files are:\\n\", emg_file_chosen, '\\n', vent_file_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EMG and ventilator data recordings from the selected folders.\n",
    "data_emg = Poly5Reader(emg_file_chosen)\n",
    "data_vent = Poly5Reader(vent_file_chosen)\n",
    "data_emg_samples = data_emg.samples[:data_emg.num_samples]\n",
    "fs_emg = data_emg.sample_rate\n",
    "data_vent_samples = data_vent.samples[:data_vent.num_samples]\n",
    "fs_vent = data_vent.sample_rate\n",
    "\n",
    "# Define the time series of the EMG and ventilator recordings\n",
    "y_emg = data_emg_samples\n",
    "# y_emg = data_emg_samples[:, :350*2048]\n",
    "# Reshufle the channels if necessary\n",
    "# y_emg = np.array([-data_emg_samples[0, :], \n",
    "#                    data_emg_samples[1, :], \n",
    "#                    data_emg_samples[2, :]])\n",
    "# # Reshufle the channels if necessary\n",
    "# y_emg = np.array([data_emg_samples[2, :], \n",
    "#                   data_emg_samples[0, :], \n",
    "#                   data_emg_samples[1, :]])\n",
    "y_vent = data_vent_samples\n",
    "\n",
    "# Define the time axes\n",
    "t_emg = np.array([i/fs_emg for i in range(len(y_emg[0, :]))])\n",
    "t_vent = np.array([i/fs_vent for i in range(len(y_vent[0, :]))])\n",
    "\n",
    "# Default settings for window of interest\n",
    "# manoeuvres (Pocc)\n",
    "# t_start_default = t_vent[-1]-61\n",
    "# t_end_default = t_vent[-1]-1\n",
    "t_start_default = t_vent[0]\n",
    "t_end_default = t_vent[-1]\n",
    "\n",
    "del data_emg_samples, data_vent_samples, data_emg, data_vent\n",
    "\n",
    "btn_plt_raw = widgets.Dropdown(\n",
    "    options=['Yes', 'No'],\n",
    "    value='No',\n",
    "    description='Plot raw data?',\n",
    "    parasabled=False,\n",
    ")\n",
    "display(btn_plt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data if wanted\n",
    "if btn_plt_raw.value == 'Yes':\n",
    " \n",
    "    fig, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    axis[0, 0].grid(True)\n",
    "    axis[0, 0].plot(t_emg, y_emg[0])\n",
    "    axis[0, 0].set(title='sEMG leads')\n",
    "    axis[0, 0].set_ylabel('ECG (uV)')\n",
    "\n",
    "    axis[1, 0].grid(True)\n",
    "    axis[1, 0].plot(t_emg, y_emg[1])\n",
    "    axis[1, 0].set_ylabel('sEMGdi (uV)')\n",
    "    axis[1, 0].set_xlabel('t (s)')\n",
    "\n",
    "    axis[2, 0].grid(True)\n",
    "    axis[2, 0].plot(t_emg, y_emg[2])\n",
    "    axis[2, 0].set_ylabel('sEMGpara (uV)')\n",
    "    axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "    axis[0, 1].set(title='Ventilator data')\n",
    "    axis[0, 1].grid(True)\n",
    "    axis[0, 1].plot(t_vent, y_vent[0])\n",
    "    axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "    axis[1, 1].grid(True)\n",
    "    axis[1, 1].plot(t_vent, y_vent[1])\n",
    "    axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "    axis[2, 1].grid(True)\n",
    "    axis[2, 1].plot(t_vent, y_vent[2])\n",
    "    axis[2, 1].set_ylabel('V (mL)')\n",
    "    axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select the time window of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = t_start_default\n",
    "end = t_end_default\n",
    "\n",
    "start_s = int(float(start)* fs_emg)\n",
    "end_s = min([int(float(end)*fs_emg), len(y_emg[0,:])-1])\n",
    "start_vent_s = int(float(start)* fs_vent)\n",
    "end_vent_s = min(\n",
    "    [int(float(end)* fs_vent), len(y_vent[0,:])-1]\n",
    ")\n",
    "\n",
    "fig_w = (int(end_vent_s)-int(start_vent_s))//(fs_vent*80)*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.a. ECG properties extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter raw EMG signals according to AHA 1990 guidelines\n",
    "y_emg_ECG_filt_AHA = filt.emg_bandpass_butter_sample(y_emg, 0.05, 150, fs_emg)\n",
    "\n",
    "y_emg_ECG_filt = filt.emg_bandpass_butter_sample(y_emg, 1, 80, fs_emg)\n",
    "# y_emg_ECG_filt = y_emg\n",
    "\n",
    "# # See https://ieeexplore.ieee.org/document/10290007 for performance\n",
    "# ecg_method = 'Zong'      # 'neurokit', 'hamilton2002', 'pantompkins1985', 'engzeemod2012'\n",
    "\n",
    "ecg_dicts = dict()\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    ecg_dicts[channel] = dict()\n",
    "\n",
    "# RMS and peak detection settings\n",
    "RMS_window_ecg_ms = 50\n",
    "RMS_windows_samp = int(RMS_window_ecg_ms / 1000 *  fs_emg)\n",
    "distance = fs_emg//10\n",
    "\n",
    "# Moving baseline parameters\n",
    "w_moving_baseline = 5 * fs_emg\n",
    "\n",
    "# ecg_type = 'raw'    # 'clean'\n",
    "channel = 'ecg'\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "T_ecg_bin_w = 0.1\n",
    "\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    y_emg_ECG_filt[idx, :]\n",
    "    ecg_dicts[channel]['raw'] = y_emg[idx, :]\n",
    "    ecg_dicts[channel]['filt'] = y_emg_ECG_filt[idx, :]\n",
    "    ecg_dicts[channel]['filt_AHA'] = y_emg_ECG_filt_AHA[idx, :]\n",
    "    \n",
    "    pre_samp = int(np.ceil(RMS_windows_samp/2))\n",
    "    post_samp = int(np.floor(RMS_windows_samp/2))\n",
    "    padding_pre = np.zeros((pre_samp,))\n",
    "    padding_end = np.zeros((post_samp,))\n",
    "    ecg_dicts[channel]['filt_padded'] = np.concatenate(\n",
    "         (padding_pre, ecg_dicts[channel]['filt'], padding_end))\n",
    "\n",
    "    ecg_dicts[channel]['rms'] = evl.full_rolling_rms(\n",
    "        ecg_dicts[channel]['filt_padded'], \n",
    "        RMS_windows_samp)\n",
    "    \n",
    "    ecg_dicts[channel]['rms'] = ecg_dicts[channel]['rms'][:-RMS_windows_samp]\n",
    "    \n",
    "    prominence = 0.01*(np.percentile(ecg_dicts[channel]['rms'], 95) \n",
    "                  - min(ecg_dicts[channel]['rms']))\n",
    "    \n",
    "    peaks, _ = scipy.signal.find_peaks(ecg_dicts[channel]['rms'], \n",
    "                                       prominence=prominence,\n",
    "                                       distance=distance)\n",
    "    ecg_dicts[channel]['peak_df'] = pd.DataFrame({\"peak_idx\":np.array(peaks)})\n",
    "    ecg_dicts[channel]['method'] = 'custom'\n",
    "    \n",
    "    ecg_dicts[channel]['mb_rms'] = moving_baseline(ecg_dicts[channel]['rms'], fs_emg, w_moving_baseline)\n",
    "    ecg_dicts[channel]['mb_filt'] = moving_baseline(ecg_dicts[channel]['filt'], fs_emg, w_moving_baseline)\n",
    "\n",
    "\n",
    "len(ecg_dicts['ecg']['peak_df']), len(ecg_dicts['di']['peak_df']), len(ecg_dicts['para']['peak_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. On- and offset detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_window = 20   # 1/slope_window\n",
    "slope_order = fs_emg//slope_window\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    # print(channel)\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    ecg_dicts[channel]['d_dt_rms'] = (ecg_dicts[channel]['rms'][1:] - ecg_dicts[channel]['rms'][:-1])*fs_emg\n",
    "    peak_idx_list  = peak_df[\"peak_idx\"].values\n",
    "    \n",
    "    local_extremes_vec_up = scipy.signal.argrelextrema(\n",
    "        ecg_dicts[channel]['d_dt_rms'], np.greater, order=slope_order)[0]\n",
    "    idxs_mat_up = (np.matlib.repmat(local_extremes_vec_up, len(peak_idx_list), 1) \n",
    "                - np.matlib.repmat(peak_idx_list, len(local_extremes_vec_up), 1).T)\n",
    "\n",
    "    loc_crossings_up = np.argwhere(np.diff(np.sign(idxs_mat_up)) != 0)\n",
    "    loc_crossings_up = loc_crossings_up[:, 1]\n",
    "\n",
    "    local_extremes_vec_down = scipy.signal.argrelextrema(\n",
    "        ecg_dicts[channel]['d_dt_rms'], np.less, order=slope_order)[0]\n",
    "    idxs_mat_down = (np.matlib.repmat(local_extremes_vec_down, len(peak_idx_list), 1) \n",
    "                - np.matlib.repmat(peak_idx_list, len(local_extremes_vec_down), 1).T)\n",
    "\n",
    "    loc_crossings_down = np.argwhere(np.diff(np.sign(idxs_mat_down)) != 0)\n",
    "    loc_crossings_down = loc_crossings_down[:, 1] + 1\n",
    "\n",
    "    peak_upslope_idx = local_extremes_vec_up[loc_crossings_up]\n",
    "    peak_downslope_idx = local_extremes_vec_down[loc_crossings_down]\n",
    "\n",
    "    len_starts = len(peak_upslope_idx)\n",
    "    len_ends = len(peak_downslope_idx)\n",
    "    len_pks = len(peak_idx_list)\n",
    "    min_len = min([len_starts, len_pks, len_ends])\n",
    "    \n",
    "    # Align starts and ends\n",
    "    perc_start_bf_prev_end = np.sum((peak_upslope_idx[1:min_len]<\n",
    "                            peak_downslope_idx[0:min_len-1]))/(min_len-1)\n",
    "    if (perc_start_bf_prev_end > 0.5):\n",
    "        # Start misaligned with ends (first start missing)\n",
    "        peak_upslope_idx = peak_upslope_idx[1:] \n",
    "\n",
    "    len_starts = len(peak_upslope_idx)\n",
    "    len_ends = len(peak_downslope_idx)\n",
    "    len_pks = len(peak_idx_list)\n",
    "    min_len = min([len_starts, len_pks, len_ends])\n",
    "    perc_ends_bf_start = np.sum((peak_upslope_idx[0:min_len]>\n",
    "                            peak_downslope_idx[0:min_len]))/(min_len)\n",
    "    if (perc_ends_bf_start > 0.5):\n",
    "        # Start misaligned with ends (first start missing)\n",
    "        peak_downslope_idx = peak_downslope_idx[1:] \n",
    "\n",
    "    perc_ends_after_next_start = np.sum((peak_upslope_idx[1:min_len]>\n",
    "                            peak_downslope_idx[0:min_len-1]))/(min_len-1)\n",
    "\n",
    "    if len(peak_upslope_idx) != len(peak_downslope_idx):\n",
    "        if ((len(peak_upslope_idx) > len(peak_downslope_idx))\n",
    "            & ((peak_upslope_idx[-2] == peak_upslope_idx[-1]))):\n",
    "            # Last detected upslope the same for last two peaks\n",
    "            peak_upslope_idx = peak_upslope_idx[:-1]\n",
    "            \n",
    "        if peak_upslope_idx[-1] > peak_downslope_idx[-1]:\n",
    "            # Last detected upslope after last detected downslope \n",
    "            peak_upslope_idx = peak_upslope_idx[:-1]\n",
    "\n",
    "        if ((peak_upslope_idx[-1] < peak_downslope_idx[-1])\n",
    "            & (peak_upslope_idx[-1] < peak_downslope_idx[-2])):\n",
    "            # Two downslopes after last detected upslope\n",
    "            peak_downslope_idx = peak_downslope_idx[:-1]\n",
    "\n",
    "\n",
    "    \n",
    "    if len(peak_upslope_idx) != len(peak_downslope_idx):\n",
    "        print(channel)\n",
    "        print('Error: Up- and downslope arrays not of equal length!')\n",
    "        len_starts = len(peak_upslope_idx)\n",
    "        len_ends = len(peak_downslope_idx)\n",
    "        len_pks = len(peak_idx_list)\n",
    "        min_len = min([len_starts, len_pks, len_ends])\n",
    "        print(len_starts, len_pks, len_ends)\n",
    "    \n",
    "    \n",
    "    if ((len(peak_upslope_idx) < len(peak_idx_list))\n",
    "        | (len(peak_downslope_idx) < len(peak_idx_list))):\n",
    "        len_starts = len(peak_upslope_idx)\n",
    "        len_ends = len(peak_downslope_idx)\n",
    "        len_pks = len(peak_idx_list)\n",
    "        min_len = min([len_starts, len_pks, len_ends])\n",
    "        perc_pk_bf_next_start = np.sum((peak_idx_list[:min_len]<\n",
    "                                peak_upslope_idx[:min_len]))/min_len\n",
    "        if perc_pk_bf_next_start > 0.5:\n",
    "            peak_df = peak_df.drop([0]).reset_index(drop=True)\n",
    "            peak_idx_list = peak_df[\"peak_idx\"].values\n",
    "\n",
    "    if ((len(peak_upslope_idx) < len(peak_idx_list))\n",
    "        | (len(peak_downslope_idx) < len(peak_idx_list))):\n",
    "        peak_idx_bf_start = np.nonzero(\n",
    "            peak_idx_list < peak_upslope_idx[0])[0].tolist()\n",
    "        peak_idx_after_end = np.nonzero(\n",
    "            peak_idx_list > peak_downslope_idx[-1])[0].tolist()\n",
    "        \n",
    "        delete_idx = peak_idx_bf_start + peak_idx_after_end\n",
    "\n",
    "        peak_df = peak_df.drop(delete_idx).reset_index(drop=True)\n",
    "        peak_idx_list = peak_df[\"peak_idx\"].values\n",
    "\n",
    "    if ((len(peak_upslope_idx) < len(peak_idx_list))\n",
    "        | (len(peak_downslope_idx) < len(peak_idx_list))):\n",
    "        # Multiple peaks between last start and last end\n",
    "\n",
    "        first_peaks = np.nonzero(\n",
    "            (peak_idx_list > peak_upslope_idx[0])\n",
    "            & (peak_idx_list < peak_downslope_idx[-1]))[0].tolist()\n",
    "        \n",
    "        last_peaks = np.nonzero(\n",
    "            (peak_idx_list > peak_upslope_idx[-1])\n",
    "            & (peak_idx_list < peak_downslope_idx[-1]))[0].tolist()\n",
    "        \n",
    "        if len(last_peaks) > 1:\n",
    "            delete_idx = last_peaks[1:]\n",
    "\n",
    "        peak_df = peak_df.drop(delete_idx).reset_index(drop=True)\n",
    "        peak_idx_list = peak_df[\"peak_idx\"].values\n",
    "\n",
    "\n",
    "    if ((len(peak_upslope_idx) < len(peak_idx_list))\n",
    "        | (len(peak_downslope_idx) < len(peak_idx_list))):\n",
    "        print(channel)\n",
    "        print('Error: Peak array not of equal length with up- and downslope '\n",
    "              +'arrays!')\n",
    "        len_starts = len(peak_upslope_idx)\n",
    "        len_ends = len(peak_downslope_idx)\n",
    "        len_pks = len(peak_idx_list)\n",
    "        min_len = min([len_starts, len_pks, len_ends])\n",
    "        print(len_starts, len_pks, len_ends)\n",
    "\n",
    "    peak_df['peak_upslope_idx'] = peak_upslope_idx\n",
    "    peak_df['peak_upslope_val'] = \\\n",
    "        ecg_dicts[channel]['d_dt_rms'][peak_upslope_idx]\n",
    "\n",
    "    peak_df['peak_downslope_idx'] = peak_downslope_idx\n",
    "    peak_df['peak_downslope_val'] = \\\n",
    "        ecg_dicts[channel]['d_dt_rms'][peak_downslope_idx]\n",
    "    \n",
    "    ecg_dicts[channel]['peak_df'] = peak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_starts = len(peak_upslope_idx)\n",
    "# len_pks = len(peak_idx_list)\n",
    "# len_ends = len(peak_downslope_idx)\n",
    "# # min_len = min([len_starts, len_pks, len_ends])\n",
    "# len_RMS = len(ecg_dicts[channel]['rms'])\n",
    "\n",
    "# # perc_start_bf_prev_end = np.sum((peak_upslope_idx[1:min_len]<\n",
    "# #                             peak_downslope_idx[0:min_len-1]))/(min_len-1)\n",
    "\n",
    "# perc_ends_bf_start = np.sum((peak_upslope_idx[0:min_len]>\n",
    "#                             peak_downslope_idx[0:min_len]))/(min_len)\n",
    "\n",
    "# len_starts, len_pks, len_ends\n",
    "# len_RMS-peak_upslope_idx[-10:], len_RMS-peak_idx_list[-10:], len_RMS-peak_downslope_idx[-10:]\n",
    "# peak_upslope_idx[:10], peak_idx_list[:10], peak_downslope_idx[:10], perc_start_bf_prev_end\n",
    "\n",
    "\n",
    "# # perc_ends_bf_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove peaks where detected up- or downslope is below baseline\n",
    "\n",
    "# for idx, channel in enumerate(channel_list): \n",
    "#     peak_df = ecg_dicts[channel]['peak_df']\n",
    "#     del_up_idx = np.nonzero(\n",
    "#         ecg_dicts[channel]['rms'][peak_df['peak_upslope_idx'].values] \n",
    "#         < ecg_dicts[channel]['mb_rms'][peak_df['peak_upslope_idx'].values])[0].tolist()\n",
    "    \n",
    "#     del_down_idx = np.nonzero(\n",
    "#         ecg_dicts[channel]['rms'][peak_df['peak_downslope_idx'].values] <\n",
    "#         ecg_dicts[channel]['mb_rms'][peak_df['peak_downslope_idx'].values])[0].tolist()\n",
    "\n",
    "#     delete_idx = del_up_idx + del_down_idx\n",
    "#     peak_df = peak_df.drop(delete_idx).reset_index(drop=True)\n",
    "\n",
    "#     ecg_dicts[channel]['peak_df'] = peak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate on- and offsets from slopes\n",
    "for idx, channel in enumerate(channel_list):   \n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    y_vals = (ecg_dicts[channel]['rms'][peak_df['peak_upslope_idx'].values])\n",
    "        # - ecg_dicts[channel]['mb_rms'][peak_df['peak_upslope_idx'].values])\n",
    "    dy_dt_vals = peak_df['peak_upslope_val'].values\n",
    "\n",
    "    peak_df['peak_upslope_idx_ds'] = np.array(\n",
    "        y_vals * fs_emg // (dy_dt_vals), dtype=int).astype(np.int64)\n",
    "\n",
    "    peak_df['peak_upslope_start_s'] = \\\n",
    "        peak_df['peak_upslope_idx'] - peak_df['peak_upslope_idx_ds']\n",
    "    peak_df.loc[peak_df['peak_upslope_start_s'] < 0, 'peak_upslope_start_s'] = 0\n",
    "    \n",
    "    y_vals = (ecg_dicts[channel]['rms'][peak_df['peak_downslope_idx'].values])\n",
    "        #  -  ecg_dicts[channel]['mb_rms'][peak_df['peak_upslope_idx'].values])\n",
    "    dy_dt_vals = peak_df['peak_downslope_val'].values\n",
    "\n",
    "    peak_df['peak_downslope_idx_ds'] = np.array(\n",
    "        y_vals * fs_emg // (dy_dt_vals), dtype=int).astype(np.int64)\n",
    "    \n",
    "    peak_df['peak_downslope_end_s'] = \\\n",
    "        peak_df['peak_downslope_idx'] - peak_df['peak_downslope_idx_ds']\n",
    "    \n",
    "    peak_df.loc[\n",
    "        peak_df['peak_downslope_end_s'] >= len(ecg_dicts[channel]['rms']), \n",
    "        'peak_downslope_end_s'] = len(ecg_dicts[channel]['rms']) - 1\n",
    "    \n",
    "    ecg_dicts[channel]['peak_df'] = peak_df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin_edges[1:], hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "# for idx, channel in enumerate(channel_list):\n",
    "#     peak_df = ecg_dicts[channel]['peak_df']\n",
    "\n",
    "#     axis[idx, 0].grid(True)\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['raw'] - np.percentile(ecg_dicts[channel]['raw'], 5))\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'])\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_filt'])\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_rms'])\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['rms'])\n",
    "#     axis[idx, 0].plot(t_emg[peak_df['peak_upslope_idx'].values], \n",
    "#                       ecg_dicts[channel]['rms'][\n",
    "#                           peak_df['peak_upslope_idx'].values], 'rx')\n",
    "#     axis[idx, 0].plot(t_emg[peak_df['peak_downslope_idx'].values], \n",
    "#                       ecg_dicts[channel]['rms'][\n",
    "#                           peak_df['peak_downslope_idx'].values], 'rx')\n",
    "\n",
    "#     axis[idx, 0].plot(t_emg[peak_df['peak_upslope_start_s'].values], \n",
    "#                       ecg_dicts[channel]['mb_rms'][\n",
    "#                           peak_df['peak_upslope_start_s'].values], 'mx')\n",
    "#     axis[idx, 0].plot(t_emg[peak_df['peak_downslope_end_s'].values], \n",
    "#                       ecg_dicts[channel]['mb_rms'][\n",
    "#                           peak_df['peak_downslope_end_s'].values], 'kx')\n",
    "\n",
    "#     axis[idx, 0].plot(t_emg[peak_df['peak_idx']], \n",
    "#                       ecg_dicts[channel]['rms'][peak_df['peak_idx']], '*r')\n",
    "    \n",
    "#     axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "# axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "# axis[0, 0].set(title='sEMG leads')\n",
    "# axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "# axis[0, 1].set(title='Ventilator data')\n",
    "# axis[0, 1].grid(True)\n",
    "# axis[0, 1].plot(t_vent, y_vent[0])\n",
    "# axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "# axis[1, 1].grid(True)\n",
    "# axis[1, 1].plot(t_vent, y_vent[1])\n",
    "# axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "# axis[2, 1].grid(True)\n",
    "# axis[2, 1].plot(t_vent, y_vent[2])\n",
    "# axis[2, 1].set_ylabel('V (mL)')\n",
    "# axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Eliminate peaks based on duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hist_ecg, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6), sharex=True)\n",
    "bin_w = 0.01\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    d_peaks = (peak_df['peak_downslope_end_s'].values\n",
    "               - peak_df['peak_upslope_start_s'].values)/fs_emg\n",
    "\n",
    "    hist, bin_edges = np.histogram(d_peaks, bins=[x*bin_w for x in \n",
    "                      range(int(max(d_peaks)/bin_w)+2)])\n",
    "    bin_edges = bin_edges[1:]\n",
    "    pks, _ = scipy.signal.find_peaks(hist, height=max(hist)/10)\n",
    "\n",
    "    axis[idx].plot(bin_edges,hist)\n",
    "    axis[idx].plot(bin_edges[pks],hist[pks], 'rx')\n",
    "    axis[idx].set_title(channel)\n",
    "    axis[idx].set_xlabel('Peak duration (s)')\n",
    "\n",
    "    ecg_dicts[channel]['qrs_duration'] = bin_edges[pks[0]]\n",
    "    d_thres = 0.25 * bin_edges[pks[0]] + bin_edges[pks[0]]\n",
    "    peak_df['included'] = (d_peaks <= d_thres)\n",
    "\n",
    "    ecg_dicts[channel]['peak_df'] = peak_df\n",
    "\n",
    "    axis[idx].set_xlim([0, (np.round(bin_edges[pks[-1]]/0.5)+1)*0.5])\n",
    "\n",
    "axis[0].set_ylabel('Bin count (.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, channel in enumerate(channel_list):\n",
    "    print(ecg_dicts[channel]['qrs_duration'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    axis[idx, 0].grid(True)\n",
    "    # axis[idx, 0].plot(t_emg, ecg_dicts[channel]['raw'] - np.percentile(ecg_dicts[channel]['raw'], 5))\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    incl_pks = (peak_df['included'] == True)\n",
    "    excl_pks = (peak_df['included'] == False)\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'])\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['rms'])\n",
    "\n",
    "\n",
    "    axis[idx, 0].plot(t_emg[peak_df.loc[incl_pks, 'peak_idx'].values], \n",
    "                      ecg_dicts[channel]['rms'][peak_df.loc[incl_pks, 'peak_idx'].values], '*g')\n",
    "    axis[idx, 0].plot(t_emg[peak_df.loc[excl_pks, 'peak_idx'].values], \n",
    "                      ecg_dicts[channel]['rms'][peak_df.loc[excl_pks, 'peak_idx'].values], '*r')\n",
    "    \n",
    "    axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 0].set(title='sEMG leads')\n",
    "axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 1].set(title='Ventilator data')\n",
    "axis[0, 1].grid(True)\n",
    "axis[0, 1].plot(t_vent, y_vent[0])\n",
    "axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "axis[1, 1].grid(True)\n",
    "axis[1, 1].plot(t_vent, y_vent[1])\n",
    "axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "axis[2, 1].grid(True)\n",
    "axis[2, 1].plot(t_vent, y_vent[2])\n",
    "axis[2, 1].set_ylabel('V (mL)')\n",
    "axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop excluded peaks\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    \n",
    "    excl_pks_idx = peak_df.index[peak_df['included'].values == False].values\n",
    "    # print(excl_pks_idx)\n",
    "    peak_df = peak_df.drop(excl_pks_idx).reset_index(drop=True)\n",
    "\n",
    "    ecg_dicts[channel]['peak_df'] = peak_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "# for idx, channel in enumerate(channel_list):\n",
    "#     axis[idx, 0].grid(True)\n",
    "#     # axis[idx, 0].plot(t_emg, ecg_dicts[channel]['raw'] - np.percentile(ecg_dicts[channel]['raw'], 5))\n",
    "#     peak_df = ecg_dicts[channel]['peak_df']\n",
    "#     incl_pks = (peak_df['included'] == True)\n",
    "#     excl_pks = (peak_df['included'] == False)\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'], 'tab:blue')\n",
    "#     axis[idx, 0].plot(t_emg, ecg_dicts[channel]['rms'], 'tab:red')\n",
    "\n",
    "\n",
    "#     axis[idx, 0].plot(t_emg[peak_df.loc[incl_pks, 'peak_idx'].values], \n",
    "#                       ecg_dicts[channel]['rms'][peak_df.loc[incl_pks, 'peak_idx'].values], '*g')\n",
    "#     axis[idx, 0].plot(t_emg[peak_df.loc[excl_pks, 'peak_idx'].values], \n",
    "#                       ecg_dicts[channel]['rms'][peak_df.loc[excl_pks, 'peak_idx'].values], '*r')\n",
    "    \n",
    "#     axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "# axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "# axis[0, 0].set(title='sEMG leads')\n",
    "# axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "# axis[0, 1].set(title='Ventilator data')\n",
    "# axis[0, 1].grid(True)\n",
    "# axis[0, 1].plot(t_vent, y_vent[0])\n",
    "# axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "# axis[1, 1].grid(True)\n",
    "# axis[1, 1].plot(t_vent, y_vent[1])\n",
    "# axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "# axis[2, 1].grid(True)\n",
    "# axis[2, 1].plot(t_vent, y_vent[2])\n",
    "# axis[2, 1].set_ylabel('V (mL)')\n",
    "# axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Eliminate peaks based on alignment with peaks in other channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6))\n",
    "bin_w = 0.05\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    \n",
    "    T_peaks = (peak_df['peak_idx'].values[1:]\n",
    "               - peak_df['peak_idx'].values[:-1])/fs_emg\n",
    "\n",
    "    hist, bin_edges = np.histogram(T_peaks, bins=[x*bin_w for x in \n",
    "                      range(int(max(T_peaks)/bin_w)+2)])\n",
    "    bin_edges = bin_edges[1:]\n",
    "    pks, _ = scipy.signal.find_peaks(hist, height=max(hist)/50)\n",
    "\n",
    "    axis[idx].plot(bin_edges,hist)\n",
    "    axis[idx].plot(bin_edges[pks],hist[pks], 'rx')\n",
    "    axis[idx].set_title(channel)\n",
    "    axis[idx].set_xlabel('Interpeak time (s)')\n",
    "\n",
    "    ecg_dicts[channel]['T_interpeak'] = bin_edges[pks]\n",
    "    ecg_dicts[channel]['T_interpeak_counts'] = hist[pks]\n",
    "\n",
    "    print(channel)\n",
    "    print(ecg_dicts[channel]['T_interpeak'])\n",
    "\n",
    "\n",
    "axis[0].set_ylabel('Bin count (.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "\n",
    "ecg_peaks = ecg_dicts['ecg']['peak_df']['peak_idx']\n",
    "di_peaks = ecg_dicts['di']['peak_df']['peak_idx']\n",
    "para_peaks = ecg_dicts['para']['peak_df']['peak_idx']\n",
    "\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    channel_peaks = peak_df['peak_idx'].values\n",
    "    ecg_nearby = np.abs(np.matlib.repmat(channel_peaks, len(ecg_peaks), 1) \n",
    "                - np.matlib.repmat(ecg_peaks, len(channel_peaks), 1).T)\n",
    "    loc_ecg_idx = np.argmin(ecg_nearby, axis=0)\n",
    "    loc_ecg = ecg_peaks[loc_ecg_idx]\n",
    "\n",
    "    di_nearby = np.abs(np.matlib.repmat(channel_peaks, len(di_peaks), 1) \n",
    "                - np.matlib.repmat(di_peaks, len(channel_peaks), 1).T)\n",
    "    loc_di_idx = np.argmin(di_nearby, axis=0)\n",
    "    loc_di = di_peaks[loc_di_idx]\n",
    "\n",
    "    para_nearby = np.abs(np.matlib.repmat(channel_peaks, len(para_peaks), 1) \n",
    "                - np.matlib.repmat(para_peaks, len(channel_peaks), 1).T)\n",
    "    loc_para_idx = np.argmin(para_nearby, axis=0)\n",
    "    loc_para = para_peaks[loc_para_idx]\n",
    "\n",
    "    sum_nearby = (np.array(abs(loc_ecg-channel_peaks)) \n",
    "                  + np.array(abs(loc_di-channel_peaks))\n",
    "                  + np.array(abs(loc_para-channel_peaks)))\n",
    "    \n",
    "    peak_df['sum_nearby'] = sum_nearby/fs_emg/3\n",
    "    peak_df['included'] = (peak_df['sum_nearby'].values <=\n",
    "                           ecg_dicts[channel]['qrs_duration']/3)\n",
    "\n",
    "    ecg_dicts[channel]['peak_df'] = peak_df\n",
    "\n",
    "fig, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6), sharex=True)\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    rms_t = ecg_dicts[channel]['rms'] - ecg_dicts[channel]['mb_rms']\n",
    "    \n",
    "    sum_nearby = (peak_df['sum_nearby'].values / \n",
    "                  ecg_dicts[channel]['qrs_duration'])\n",
    "    \n",
    "    peak_amp = rms_t[peak_df['peak_idx'].values]\n",
    "\n",
    "    axis[idx].plot(sum_nearby[sum_nearby > 1/3],\n",
    "                   peak_amp[sum_nearby > 1/3], 'rx')\n",
    "    axis[idx].plot(sum_nearby[sum_nearby <= 1/3],\n",
    "                   peak_amp[sum_nearby <= 1/3], 'g*')\n",
    "    axis[idx].set_xlabel('sum_nearby')\n",
    "\n",
    "axis[0].set_ylabel('Peak amp (uV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = ['ecg', 'di', 'para']\n",
    "fig, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    peak_df['included'] = (peak_df['sum_nearby'].values <=\n",
    "                           ecg_dicts[channel]['qrs_duration']/3)\n",
    "\n",
    "    ecg_dicts[channel]['peak_df'] = peak_df\n",
    "\n",
    "\n",
    "    axis[idx, 0].grid(True)\n",
    "    incl_pks = (peak_df['included'] == True)\n",
    "    excl_pks = (peak_df['included'] == False)\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'],'tab:blue')\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_filt'],'tab:red')\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['rms'],'tab:orange')\n",
    "\n",
    "\n",
    "    axis[idx, 0].plot(t_emg[peak_df.loc[incl_pks, 'peak_idx'].values], \n",
    "                      ecg_dicts[channel]['rms'][peak_df.loc[incl_pks, 'peak_idx'].values], '*g')\n",
    "    axis[idx, 0].plot(t_emg[peak_df.loc[excl_pks, 'peak_idx'].values], \n",
    "                      ecg_dicts[channel]['rms'][peak_df.loc[excl_pks, 'peak_idx'].values], '*r')\n",
    "    \n",
    "    axis[idx, 0].plot(t_emg[peak_df.loc[incl_pks, 'peak_upslope_start_s'].values], \n",
    "                      ecg_dicts[channel]['filt'][peak_df.loc[incl_pks, 'peak_upslope_start_s'].values], 'xm')\n",
    "    axis[idx, 0].plot(t_emg[peak_df.loc[incl_pks, 'peak_downslope_end_s'].values], \n",
    "                    ecg_dicts[channel]['filt'][peak_df.loc[incl_pks, 'peak_downslope_end_s'].values], 'xm')\n",
    "    \n",
    "    axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 0].set(title='sEMG leads')\n",
    "axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 1].set(title='Ventilator data')\n",
    "axis[0, 1].grid(True)\n",
    "axis[0, 1].plot(t_vent, y_vent[0])\n",
    "axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "axis[1, 1].grid(True)\n",
    "axis[1, 1].plot(t_vent, y_vent[1])\n",
    "axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "axis[2, 1].grid(True)\n",
    "axis[2, 1].plot(t_vent, y_vent[2])\n",
    "axis[2, 1].set_ylabel('V (mL)')\n",
    "axis[2, 1].set_xlabel('t (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop excluded peaks\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    \n",
    "    excl_pks_idx = peak_df.index[peak_df['included'].values == False].values\n",
    "    peak_df = peak_df.drop(excl_pks_idx).reset_index(drop=True)\n",
    "\n",
    "    ecg_dicts[channel]['peak_df'] = peak_df\n",
    "\n",
    "fig, axis = plt.subplots(nrows=1, ncols=3, figsize=(10, 6), \n",
    "                         sharex=True, sharey=True)\n",
    "bin_w = 0.05\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    \n",
    "    T_peaks = (peak_df['peak_idx'].values[1:]\n",
    "               - peak_df['peak_idx'].values[:-1])/fs_emg\n",
    "\n",
    "    hist, bin_edges = np.histogram(T_peaks, bins=[x*bin_w for x in \n",
    "                      range(int(max(T_peaks)/bin_w)+2)])\n",
    "    bin_edges = bin_edges[1:]\n",
    "    pks, _ = scipy.signal.find_peaks(hist, height=max(hist)/50)\n",
    "\n",
    "    axis[idx].plot(bin_edges,hist)\n",
    "    axis[idx].plot(bin_edges[pks],hist[pks], 'rx')\n",
    "    axis[idx].set_title(channel)\n",
    "    axis[idx].set_xlabel('Interpeak time (s)')\n",
    "\n",
    "    ecg_dicts[channel]['T_interpeak'] = bin_edges[pks]\n",
    "    ecg_dicts[channel]['T_interpeak_counts'] = hist[pks]\n",
    "\n",
    "    print(channel)\n",
    "    print(ecg_dicts[channel]['T_interpeak'])\n",
    "\n",
    "\n",
    "axis[0].set_ylabel('Bin count (.)')\n",
    "axis[0].set_xlim([0, 2.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max amplitude and AUC\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    peaks_list = peak_df['peak_idx'].values\n",
    "    starts_list = peak_df['peak_upslope_start_s'].values\n",
    "    ends_list = peak_df['peak_downslope_end_s'].values\n",
    "\n",
    "    xp = np.array([starts_list, ends_list]).flatten('F').tolist()\n",
    "    fp = ecg_dicts[channel]['filt'][xp]\n",
    "    ecg_dicts[channel]['start_end_interp'] = numpy.interp(\n",
    "        t_emg, np.array(xp)/fs_emg, fp)\n",
    "\n",
    "    min_vals = []\n",
    "    min_idxs = []\n",
    "    max_vals = []\n",
    "    max_idxs = []\n",
    "    minmax = []\n",
    "    auc_baseline = []\n",
    "    auc_interp = []\n",
    "    drop_pk_nr = []\n",
    "    \n",
    "    for pk_nr, pk_idx  in enumerate(peaks_list):\n",
    "        _s_start = starts_list[pk_nr]\n",
    "        _s_end = ends_list[pk_nr]\n",
    "\n",
    "        if _s_end < _s_start:\n",
    "            drop_pk_nr.append(pk_nr)\n",
    "        else:\n",
    "            # _signal = ecg_dicts[channel]['filt_AHA'][_s_start:_s_end]\n",
    "            _signal_base = (ecg_dicts[channel]['filt'][_s_start:_s_end] \n",
    "                    - ecg_dicts[channel]['mb_filt'][_s_start:_s_end])\n",
    "            _signal_interp = (ecg_dicts[channel]['filt'][_s_start:_s_end] \n",
    "                    - ecg_dicts[channel]['start_end_interp'][_s_start:_s_end])\n",
    "\n",
    "            min_vals.append(np.min(_signal_base))\n",
    "            min_idxs.append(\n",
    "                np.argmin(_signal_base) + _s_start)\n",
    "            max_vals.append(np.max(_signal_base))\n",
    "            max_idxs.append(\n",
    "                np.argmax(_signal_base) + _s_start)\n",
    "            minmax.append(np.max(_signal_base) - np.min(_signal_base))\n",
    "            auc_baseline.append(np.trapz(np.abs(_signal_base),dx=1/fs_emg))\n",
    "            auc_interp.append(np.trapz(np.abs(_signal_interp),dx=1/fs_emg))\n",
    "    \n",
    "    if len(drop_pk_nr) > 0:\n",
    "        peak_df = peak_df.drop(drop_pk_nr).reset_index(drop=True)\n",
    "\n",
    "    peak_df['min_vals'] = min_vals\n",
    "    peak_df['min_idxs'] = min_idxs\n",
    "    peak_df['max_vals'] = max_vals\n",
    "    peak_df['max_idxs'] = max_idxs\n",
    "    peak_df['minmax'] = minmax\n",
    "    peak_df['auc_baseline'] = auc_baseline\n",
    "    peak_df['auc_interp'] = auc_interp\n",
    "\n",
    "    ecg_dicts[channel]['peak_df'] = peak_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t, axis = plt.subplots(nrows=3, ncols=2, figsize=(10, 6), sharex=True)\n",
    "\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    peak_idx_list = peak_df['peak_idx'].values\n",
    "    min_vals = peak_df['min_vals'].values\n",
    "    min_idxs = peak_df['min_idxs'].values\n",
    "    max_vals = peak_df['max_vals'].values\n",
    "    max_idxs = peak_df['max_idxs'].values\n",
    "    peak_starts = peak_df['peak_upslope_start_s'].values\n",
    "    peak_ends = peak_df['peak_downslope_end_s'].values\n",
    "    minmax = peak_df['minmax'].values\n",
    "\n",
    "    plot_idx = np.zeros(ecg_dicts[channel]['filt'].shape)\n",
    "    for pk_nr, peak_idx in enumerate(peak_idx_list):\n",
    "        plot_idx[peak_starts[pk_nr]:peak_ends[pk_nr]] = 1\n",
    "\n",
    "    axis[idx, 0].grid(True)\n",
    "    # axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt_AHA'])\n",
    "    # axis[idx, 0].plot(t_emg[min_idxs], \n",
    "    #                   ecg_dicts[channel]['filt_AHA'][min_idxs], '*r')\n",
    "    # axis[idx, 0].plot(t_emg[max_idxs], \n",
    "    #                   ecg_dicts[channel]['filt_AHA'][max_idxs], '*g')\n",
    "    axis[idx, 0].fill_between(\n",
    "        x=t_emg, \n",
    "        y1= ecg_dicts[channel]['filt'], \n",
    "        y2= ecg_dicts[channel]['mb_filt'],\n",
    "        where= (plot_idx == 1),\n",
    "        color= \"c\",\n",
    "        alpha= 0.5)\n",
    "    axis[idx, 0].fill_between(\n",
    "        x=t_emg, \n",
    "        y1= ecg_dicts[channel]['filt'], \n",
    "        y2= ecg_dicts[channel]['start_end_interp'],\n",
    "        where= (plot_idx == 1),\n",
    "        color= \"r\",\n",
    "        alpha= 0.5)\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'], 'tab:blue')\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_filt'], 'tab:orange')\n",
    "    axis[idx, 0].plot(t_emg[min_idxs], \n",
    "                      ecg_dicts[channel]['filt'][min_idxs], '*r')\n",
    "    axis[idx, 0].plot(t_emg[max_idxs], \n",
    "                      ecg_dicts[channel]['filt'][max_idxs], '*g')\n",
    "    \n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['filt'],'tab:blue')\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['mb_filt'],'tab:red')\n",
    "    axis[idx, 0].plot(t_emg, ecg_dicts[channel]['rms'],'tab:orange')\n",
    "    \n",
    "    axis[idx, 0].plot(t_emg[peak_starts], \n",
    "                      ecg_dicts[channel]['filt'][peak_starts], 'xm')\n",
    "    axis[idx, 0].plot(t_emg[peak_ends], \n",
    "                    ecg_dicts[channel]['filt'][peak_ends], 'xm')\n",
    "\n",
    "    axis[idx, 0].set_ylabel(channel_list[idx] + ' (uV)')\n",
    "\n",
    "axis[idx, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 0].set(title='sEMG leads')\n",
    "axis[2, 0].set_xlabel('t (s)')\n",
    "\n",
    "axis[0, 1].set(title='Ventilator data')\n",
    "axis[0, 1].grid(True)\n",
    "axis[0, 1].plot(t_vent, y_vent[0])\n",
    "axis[0, 1].set_ylabel('Paw (cmH2O)')\n",
    "\n",
    "axis[1, 1].grid(True)\n",
    "axis[1, 1].plot(t_vent, y_vent[1])\n",
    "axis[1, 1].set_ylabel('F (L/min)')\n",
    "\n",
    "axis[2, 1].grid(True)\n",
    "axis[2, 1].plot(t_vent, y_vent[2])\n",
    "axis[2, 1].set_ylabel('V (mL)')\n",
    "axis[2, 1].set_xlabel('t (s)')\n",
    "\n",
    "focus_peaks = peak_idx_list[peak_idx_list > (len(t_emg)-fs_emg*30)]\n",
    "x_start = focus_peaks[0] - fs_emg//2\n",
    "x_end = focus_peaks[2] + fs_emg//2\n",
    "axis[idx, 0].set_xlim(np.array([x_start, x_end])/fs_emg)\n",
    "\n",
    "for idx, channel in enumerate(channel_list):\n",
    "    y_min = min(ecg_dicts[channel]['filt'][x_start:x_end])\n",
    "    y_max = max([max(ecg_dicts[channel]['rms'][x_start:x_end]),\n",
    "                 max(ecg_dicts[channel]['filt'][x_start:x_end])])\n",
    "    log_base = 10 ** np.floor(np.log(y_max)/np.log(10))\n",
    "    y_min = (np.floor(y_min /log_base)-0.5) * log_base\n",
    "    y_max = (np.ceil(y_max /log_base)+0.5) * log_base\n",
    "    axis[idx, 0].set_ylim([y_min, y_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of QRS min-max amplitudes\n",
    "\n",
    "fig_hist, axis = plt.subplots(nrows=2, ncols=3, figsize=(10, 6))\n",
    "bin_w_peak_to_peak = 5\n",
    "bin_w_auc = 0.1\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "\n",
    "for idx, channel  in enumerate(channel_list):\n",
    "\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    peak_idx_list = peak_df['peak_idx'].values\n",
    "    min_vals = peak_df['min_vals'].values\n",
    "    min_idxs = peak_df['min_idxs'].values\n",
    "    max_vals = peak_df['max_vals'].values\n",
    "    max_idxs = peak_df['max_idxs'].values\n",
    "    peak_starts = peak_df['peak_upslope_start_s'].values\n",
    "    peak_ends = peak_df['peak_downslope_end_s'].values\n",
    "    minmax = peak_df['minmax'].values\n",
    "    auc = peak_df['auc_baseline'].values\n",
    "    \n",
    "    bin_w_peak_to_peak = 10**np.floor(np.log((np.percentile(minmax, 99)\n",
    "                                               - min(minmax))/20\n",
    "                                             )/np.log(10))\n",
    "    # if channel == 0:\n",
    "    #   bin_w_auc = 0.1\n",
    "    # else:\n",
    "    bin_w_auc = 10**np.round(np.log((np.percentile(auc, 90)\n",
    "                                     -np.percentile(auc, 10))/10)/np.log(10))\n",
    "\n",
    "    axis[0, idx].hist(minmax, \n",
    "                bins=[x*bin_w_peak_to_peak \n",
    "                      for x in range(int(max(minmax)/bin_w_peak_to_peak))])\n",
    "    axis[0, idx].set_title(channel)\n",
    "    axis[0, idx].set_xlabel('QRS min-max amp (uV)')\n",
    "    \n",
    "    axis[0, idx].set_xlim([np.percentile(minmax, 1), np.percentile(minmax, 99)])\n",
    "\n",
    "    axis[1, idx].hist(auc, bins=[x*bin_w_auc \n",
    "                      for x in range(int(np.percentile(auc, 99)/bin_w_auc))])\n",
    "    # axis[1, idx].set_title(channel)\n",
    "    axis[1, idx].set_xlabel('QRS AUC (uV.s)')\n",
    "    \n",
    "    axis[1, idx].set_xlim([0.9*np.percentile(auc, 5), \n",
    "                           1.1*np.percentile(auc, 95)])\n",
    "\n",
    "axis[0, 0].set_ylabel('Bin count (.)')\n",
    "\n",
    "('minmax', \n",
    " np.median(ecg_dicts['ecg']['peak_df']['minmax'].values), \n",
    " np.median(ecg_dicts['di']['peak_df']['minmax'].values), \n",
    " np.median(ecg_dicts['para']['peak_df']['minmax'].values), \n",
    " 'AUC',\n",
    " np.median(ecg_dicts['ecg']['peak_df']['auc_baseline'].values), \n",
    " np.median(ecg_dicts['di']['peak_df']['auc_baseline'].values), \n",
    " np.median(ecg_dicts['para']['peak_df']['auc_baseline'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel = 'ecg'\n",
    "# peak_df = ecg_dicts[channel]['peak_df']\n",
    "# peak_idx_list = peak_df['peak_idx'].values\n",
    "# min_vals = peak_df['min_vals'].values\n",
    "# min_idxs = peak_df['min_idxs'].values\n",
    "# max_vals = peak_df['max_vals'].values\n",
    "# max_idxs = peak_df['max_idxs'].values\n",
    "# peak_starts = peak_df['peak_upslope_start_s'].values\n",
    "# peak_ends = peak_df['peak_downslope_end_s'].values\n",
    "# minmax = peak_df['minmax'].values\n",
    "# auc = peak_df['auc_baseline'].values\n",
    "\n",
    "# np.percentile(auc, 25), np.percentile(auc, 75), 10**np.round(np.log((np.percentile(auc, 99)/20))/np.log(10))/2, np.percentile(auc, 99)/bin_w_auc, [x*bin_w_auc \n",
    "#                       for x in range(int(np.percentile(auc, 99)/bin_w_auc))][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Add the outcome data to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient + ' / ' + measurement_date + ' / ' + PS_step_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t.savefig(main_output_dir + '/' + patient + '/' + measurement_date\n",
    "              + '/' + measurement_date + '_' + patient + '_' \n",
    "              + PS_step_chosen + 'ECG_timeplots.png', \n",
    "              dpi=300)\n",
    "fig_hist.savefig(main_output_dir + '/' + patient + '/' + measurement_date\n",
    "              + '/' + measurement_date + '_' + patient + '_' \n",
    "              + PS_step_chosen + 'ECG_histograms.png', \n",
    "              dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# di_data_list = []\n",
    "# para_data_list = []\n",
    "# Paw_data_list = []\n",
    "# Vvent_data_list = []\n",
    "# ecg_data_list = []\n",
    "\n",
    "# ecg_data_all_dict = dict()\n",
    "# df_ecg_all_dict = dict()\n",
    "# channel_list = ['ecg', 'di', 'para']\n",
    "# columns_ecg_all = ['patient', 'measurement',\n",
    "#               'ecg_minmax', 'ecg_min', 'ecg_max', 'ecg_method']\n",
    "# for idx, channel  in enumerate(channel_list):\n",
    "#     ecg_data_all_dict[channel] = []\n",
    "#     df_ecg_all_dict[channel] = pd.DataFrame(ecg_data_all_dict[channel], columns=columns_ecg_all)\n",
    "\n",
    "# # PS_step_del = '002'\n",
    "# PS_step_del = PS_step_chosen\n",
    "# df_di = df_di.drop(df_di[df_di['measurement'] == PS_step_del].index)\n",
    "# df_para = df_para.drop(df_para[df_para['measurement'] == PS_step_del].index)\n",
    "# df_Paw = df_Paw.drop(df_Paw[df_Paw['measurement'] == PS_step_del].index)\n",
    "# df_Vvent = df_Vvent.drop(df_Vvent[df_Vvent['measurement'] == PS_step_del].index)\n",
    "# df_ecg = df_ecg.drop(df_ecg[df_ecg['measurement'] == PS_step_del].index)\n",
    "\n",
    "# di_data_list = list(df_di.values)W\n",
    "# para_data_list = list(df_para.values)\n",
    "# Paw_data_list = list(df_Paw.values)\n",
    "# Vvent_data_list = list(df_Vvent.values)\n",
    "\n",
    "# df_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store overall ECG parameters in a dataframe (~ table)\n",
    "columns_ecg = ['patient', 'measurement',\n",
    "              'ecg_ecg_minmax', 'ecg_method', \n",
    "              'ecg_di_minmax', 'di_method', \n",
    "              'ecg_para_minmax', 'para_method', \n",
    "              'ecg_ecg_auc', 'ecg_di_auc', 'ecg_para_auc'\n",
    "              ]\n",
    "\n",
    "df_ecg = pd.DataFrame(ecg_data_list, columns=columns_ecg)\n",
    "\n",
    "if len(df_ecg[df_ecg['measurement'] == PS_step_chosen]) == 0:\n",
    "    data_ecg_tmp = [patient, PS_step_chosen,\n",
    "                    np.median(ecg_dicts['ecg']['peak_df']['minmax'].values), \n",
    "                    ecg_dicts['ecg']['method'], \n",
    "                    np.median(ecg_dicts['di']['peak_df']['minmax'].values), \n",
    "                    ecg_dicts['di']['method'], \n",
    "                    np.median(ecg_dicts['para']['peak_df']['minmax'].values),\n",
    "                    ecg_dicts['para']['method'], \n",
    "                    np.median(ecg_dicts['ecg']['peak_df']['auc_baseline'].values), \n",
    "                    np.median(ecg_dicts['di']['peak_df']['auc_baseline'].values),\n",
    "                    np.median(ecg_dicts['para']['peak_df']['auc_baseline'].values)\n",
    "                ]\n",
    "    ecg_data_list.append(data_ecg_tmp)\n",
    "    \n",
    "    df_ecg = pd.DataFrame(ecg_data_list, columns=columns_ecg)\n",
    "else:\n",
    "    print('Data of PS step ' + PS_step_chosen + ' already added to the ' \n",
    "          + 'dataframe. Don''t add the data twice!')\n",
    "    \n",
    "df_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all ECG peaks in a in a dataframe (~ table)\n",
    "columns_ecg_all = ['patient', 'measurement',\n",
    "                   'ecg_min', 'ecg_max', 'ecg_minmax', 'ecg_method', \n",
    "                   'auc_baseline', 'auc_interp',\n",
    "                   'start_idx', 'end_idx']\n",
    "\n",
    "channel_list = ['ecg', 'di', 'para']\n",
    "for _, channel  in enumerate(channel_list):\n",
    "    peak_df = ecg_dicts[channel]['peak_df']\n",
    "    min_vals = peak_df['min_vals'].values\n",
    "    max_vals = peak_df['max_vals'].values\n",
    "    peak_starts = peak_df['peak_upslope_start_s'].values\n",
    "    peak_ends = peak_df['peak_downslope_end_s'].values\n",
    "    minmax = peak_df['minmax'].values\n",
    "    auc_baseline = peak_df['auc_baseline'].values\n",
    "    auc_interp = peak_df['auc_interp'].values\n",
    "\n",
    "    if len(df_ecg_all_dict[channel][df_ecg_all_dict[channel]['measurement'] == PS_step_chosen]) == 0:\n",
    "        for idx in range(len(minmax)):\n",
    "            data_ecg_all_tmp = [patient, PS_step_chosen,\n",
    "                                min_vals[idx],\n",
    "                                max_vals[idx],\n",
    "                                minmax[idx],\n",
    "                                ecg_dicts[channel]['method'], \n",
    "                                auc_baseline[idx],\n",
    "                                auc_interp[idx],\n",
    "                                peak_starts[idx],\n",
    "                                peak_ends[idx],\n",
    "                                ]\n",
    "        \n",
    "            ecg_data_all_dict[channel].append(data_ecg_all_tmp)\n",
    "            \n",
    "        df_ecg_all_dict[channel] = pd.DataFrame(ecg_data_all_dict[channel], \n",
    "                                                columns=columns_ecg_all)\n",
    "    else:\n",
    "        print('Data of PS step ' + PS_step_chosen + ' already added to the ' \n",
    "            + 'dataframe for channel ' +  channel + '. Don''t add the data '\n",
    "            + 'twice!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move on to the next measurement\n",
    "if PS_step_chosen in df_ecg['measurement'].to_list():\n",
    "    if PS_step_idx >= 5:\n",
    "        print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. You can continue to the '\n",
    "              + 'saving the overall data!')\n",
    "              \n",
    "    elif PS_step_chosen != list_of_numbers_string[PS_step_idx]:\n",
    "        print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. Run the next PEEP step, '\n",
    "              + 'starting at step 2C.')\n",
    "    else:\n",
    "        PS_step_idx += 1\n",
    "        if PS_step_idx >= 5:\n",
    "            print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. You can continue to the '\n",
    "              + 'saving the overall data!')\n",
    "        else:\n",
    "            print('Data of measurement ' + PS_step_chosen + ' added to the '\n",
    "              + 'dataframe. PS step ' + str(PS_step_chosen) + ' (' +\n",
    "              str(len(set(df_ecg['measurement'].values))) + '/5) is '\n",
    "              + 'successfully evaluated and stored. Run the next PEEP step, '\n",
    "              + 'starting at step 2C.')\n",
    "else:\n",
    "    print('Data of measurement ' + PS_step_chosen + ' not yet added to the ' \n",
    "        + 'dataframe!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['To next PS step'](#section_ps_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store session data if complete\n",
    "if ((len(set(df_ecg['measurement'].values)) < 5) |\n",
    "    (measurement_date != measurement_dates[date_idx])):\n",
    "    print('Warning: Not 5 PS settings evaluated yet!')\n",
    "else:\n",
    "    df_ecg.to_csv(main_output_dir + '/' + patient + '/' + measurement_date  \n",
    "              + '/' + measurement_date + '_' + patient\n",
    "              +'_ECGs.csv')\n",
    "    \n",
    "    for _, channel in enumerate(channel_list):\n",
    "   \n",
    "        df_ecg_all_dict[channel].to_csv(main_output_dir + '/' + patient + '/' \n",
    "              + measurement_date + '/' + measurement_date + '_' + patient\n",
    "              +'_ECGall_' + channel + '.csv')\n",
    "    \n",
    "    print('Notification: Data of 5 PS settings stored!')\n",
    "    print(measurement_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move on to the next measurement date if data saved\n",
    "\n",
    "if not os.path.exists(main_output_dir + '/' + patient + '/' + measurement_date  \n",
    "                      + '/' + measurement_date + '_' + patient \n",
    "                      +'_ECGall_para' + '.csv'):\n",
    "    print('Warning 1: Data not stored! Do not progress to next date!')\n",
    "elif ((len(set(df_ecg_all_dict['para']['measurement'].values)) < 5)):\n",
    "    print('Warning 2: Data not stored! Do not progress to next date!')\n",
    "elif ((date_idx < len(measurement_dates)\n",
    "         and (measurement_date != measurement_dates[date_idx]))):\n",
    "    print('Notification: Data appropriately stored and date index increased.'\n",
    "              +'You may progress to next date:')\n",
    "    print(measurement_dates[date_idx] + ' (day ' + str(date_idx+1) + '/'\n",
    "          + str(len(measurement_dates)) + ')')\n",
    "else:\n",
    "    if date_idx < len(measurement_dates)-1:\n",
    "        print('Notification: Data appropriately stored. '\n",
    "              +'You may progress to next date:')\n",
    "        \n",
    "        if measurement_date == measurement_dates[date_idx]:\n",
    "            date_idx += 1            \n",
    "            print(measurement_dates[date_idx] + ' (day ' + str(date_idx+1) + '/'\n",
    "                  + str(len(measurement_dates)) + ')')\n",
    "    else:\n",
    "        if patient == patients[patient_idx]:\n",
    "            patient_idx += 1\n",
    "            date_idx = 0\n",
    "        print('Notification: Data appropriately stored. \\n'+\n",
    "              'This was the last measurement of this patient. '\n",
    "              +'You may progress to next patient!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data anyway:\n",
    "# df_ecg.to_csv(main_output_dir + '/' + patient + '/' + measurement_date  \n",
    "#             + '/' + measurement_date + '_' + patient\n",
    "#             +'_ECGs.csv')\n",
    "\n",
    "# for _, channel in enumerate(channel_list):\n",
    "\n",
    "#     df_ecg_all_dict[channel].to_csv(main_output_dir + '/' + patient + '/' \n",
    "#             + measurement_date + '/' + measurement_date + '_' + patient\n",
    "#             +'_ECGall_' + channel + '.csv')\n",
    "\n",
    "# date_idx += 1\n",
    "# if date_idx < len(measurement_dates):\n",
    "#     print('Notification: Data appropriately stored. '\n",
    "#             +'You may progress to next date!')\n",
    "#     print(measurement_date)\n",
    "# else:\n",
    "#     if patient == patients[patient_idx]:\n",
    "#         patient_idx += 1\n",
    "#         date_idx = 0\n",
    "#     print('Notification: Data appropriately stored. \\n'+\n",
    "#             'This was the last measurement of this patient. '\n",
    "#             +'You may progress to next patient!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move on to the next measurement date\n",
    "# date_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move on to the previous measurement date\n",
    "# date_idx -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['To next measurement date'](#section_date_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move on to the next patient\n",
    "# patient_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move on to the previous patient\n",
    "# patient_idx -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['To next patient'](#section_patient_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_twice = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation of ETPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalise the ETPdi, PTPocc and NMCdi values relative to PEEP = 9 cmH2O:\n",
    "# PEEP_norm = 9\n",
    "# if len(set(df.loc[df['PEEP_set'] == PEEP_norm, 'PEEP_set'].values)) != 1:\n",
    "#     print('Warning: PEEP = ', PEEP_norm, ' cmH2O is not available yet. ',\n",
    "#           'Run that dataset first!')\n",
    "# else:\n",
    "#     # Strict\n",
    "#     PTP_PEEP9_strict = np.median(output_df.loc[\n",
    "#         quality_df_bool_strict.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'PTP_occs']\n",
    "#     )\n",
    "#     ETP_PEEP9_strict = np.median(output_df.loc[\n",
    "#         quality_df_bool_strict.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'ETP_di_occs']\n",
    "#     )\n",
    "#     output_df = output_df.assign(PTP_norm_strict=\n",
    "#                      output_df['PTP_occs'] / PTP_PEEP9_strict)\n",
    "#     output_df = output_df.assign(ETP_norm_strict=\n",
    "#                      output_df['ETP_di_occs'] / ETP_PEEP9_strict)\n",
    "#     output_df = output_df.assign(NMC_di_norm_strict=\n",
    "#                      output_df['PTP_norm_strict'] / \n",
    "#                      output_df['ETP_norm_strict'])\n",
    "#     # Tolerant\n",
    "#     PTP_PEEP9_tolerant = np.median(output_df.loc[\n",
    "#         quality_df_bool_tolerant.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'PTP_occs']\n",
    "#     )\n",
    "#     ETP_PEEP9_tolerant = np.median(output_df.loc[\n",
    "#         quality_df_bool_tolerant.all(axis=1).values\n",
    "#         & (df['PEEP_set'] == PEEP_norm), \n",
    "#         'ETP_di_occs']\n",
    "#     )\n",
    "#     output_df = output_df.assign(PTP_norm_tol=\n",
    "#                      output_df['PTP_occs'] / PTP_PEEP9_tolerant)\n",
    "#     output_df = output_df.assign(ETP_norm_tol=\n",
    "#                      output_df['ETP_di_occs'] / ETP_PEEP9_tolerant)\n",
    "#     output_df = output_df.assign(NMC_di_norm_tol=\n",
    "#                      output_df['PTP_norm_tol'] / output_df['ETP_norm_tol'])\n",
    "\n",
    "# print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the normalised NMCdi values, permissible according to the tolerant \n",
    "# # criteria\n",
    "# if len(set(df['PS_set'].values)) < 4:\n",
    "#     print('Warning: Not 4 PS settings evaluated yet!')\n",
    "# else:\n",
    "#     passed_all_tolerant_crit = quality_df_bool_strict.all(axis=1)\n",
    "\n",
    "#     bp = output_df[passed_all_tolerant_crit].plot.scatter('PEEP_set', \n",
    "#                                                    'NMC_di_norm_strict')\n",
    "#     bp.set_ylabel('Normalised NMC_di (.)')\n",
    "#     bp.set_xlabel('PEEP (cmH2O)')\n",
    "#     bp.set_title('Normalised')\n",
    "#     ylims = bp.set_ylim()\n",
    "#     bp.set_ylim((0, ylims[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "715559eda0e456e9cdc499f5ec9b632cad73616ca8207bb3c3108e6214e21bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
